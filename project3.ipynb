{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/jkranyak/project_3/blob/main/project3.ipynb",
      "authorship_tag": "ABX9TyN1F9xZSX48uXDKd75MyjTN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jkranyak/project_3/blob/main/project3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTn88MrjoCyu",
        "outputId": "c1984cf6-d275-45b4-9bb2-d6c53993f078"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install isic-cli\n",
        "!pip install isic-cli\n",
        "!pip install kaggle\n",
        "!pip install imblearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9dKgTXpPs_K",
        "outputId": "6d311841-0728-460d-dbf6-9dbeda060076"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: isic-cli in /usr/local/lib/python3.10/dist-packages (10.0.0)\n",
            "Requirement already satisfied: click>=8 in /usr/local/lib/python3.10/dist-packages (from isic-cli) (8.1.7)\n",
            "Requirement already satisfied: django-s3-file-field-client>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from isic-cli) (1.0.1)\n",
            "Requirement already satisfied: girder-cli-oauth-client<1.0.0 in /usr/local/lib/python3.10/dist-packages (from isic-cli) (0.4.0)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from isic-cli) (4.9.0)\n",
            "Requirement already satisfied: isic-metadata>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from isic-cli) (1.5.0)\n",
            "Requirement already satisfied: more-itertools in /usr/lib/python3/dist-packages (from isic-cli) (8.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from isic-cli) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from isic-cli) (2.31.0)\n",
            "Requirement already satisfied: retryable-requests in /usr/local/lib/python3.10/dist-packages (from isic-cli) (0.1.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from isic-cli) (13.7.1)\n",
            "Requirement already satisfied: sentry-sdk in /usr/local/lib/python3.10/dist-packages (from isic-cli) (1.45.0)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (from isic-cli) (8.2.3)\n",
            "Requirement already satisfied: authlib in /usr/local/lib/python3.10/dist-packages (from girder-cli-oauth-client<1.0.0->isic-cli) (1.3.0)\n",
            "Requirement already satisfied: pyxdg in /usr/local/lib/python3.10/dist-packages (from girder-cli-oauth-client<1.0.0->isic-cli) (0.28)\n",
            "Requirement already satisfied: pydantic>=2.4 in /usr/local/lib/python3.10/dist-packages (from isic-metadata>=1.2.0->isic-cli) (2.6.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->isic-cli) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->isic-cli) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->isic-cli) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->isic-cli) (2024.2.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from retryable-requests->isic-cli) (1.0.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->isic-cli) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->isic-cli) (2.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->isic-cli) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.4->isic-metadata>=1.2.0->isic-cli) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.4->isic-metadata>=1.2.0->isic-cli) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.4->isic-metadata>=1.2.0->isic-cli) (4.11.0)\n",
            "Requirement already satisfied: cryptography in /usr/lib/python3/dist-packages (from authlib->girder-cli-oauth-client<1.0.0->isic-cli) (3.4.8)\n",
            "Requirement already satisfied: isic-cli in /usr/local/lib/python3.10/dist-packages (10.0.0)\n",
            "Requirement already satisfied: click>=8 in /usr/local/lib/python3.10/dist-packages (from isic-cli) (8.1.7)\n",
            "Requirement already satisfied: django-s3-file-field-client>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from isic-cli) (1.0.1)\n",
            "Requirement already satisfied: girder-cli-oauth-client<1.0.0 in /usr/local/lib/python3.10/dist-packages (from isic-cli) (0.4.0)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from isic-cli) (4.9.0)\n",
            "Requirement already satisfied: isic-metadata>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from isic-cli) (1.5.0)\n",
            "Requirement already satisfied: more-itertools in /usr/lib/python3/dist-packages (from isic-cli) (8.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from isic-cli) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from isic-cli) (2.31.0)\n",
            "Requirement already satisfied: retryable-requests in /usr/local/lib/python3.10/dist-packages (from isic-cli) (0.1.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from isic-cli) (13.7.1)\n",
            "Requirement already satisfied: sentry-sdk in /usr/local/lib/python3.10/dist-packages (from isic-cli) (1.45.0)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (from isic-cli) (8.2.3)\n",
            "Requirement already satisfied: authlib in /usr/local/lib/python3.10/dist-packages (from girder-cli-oauth-client<1.0.0->isic-cli) (1.3.0)\n",
            "Requirement already satisfied: pyxdg in /usr/local/lib/python3.10/dist-packages (from girder-cli-oauth-client<1.0.0->isic-cli) (0.28)\n",
            "Requirement already satisfied: pydantic>=2.4 in /usr/local/lib/python3.10/dist-packages (from isic-metadata>=1.2.0->isic-cli) (2.6.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->isic-cli) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->isic-cli) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->isic-cli) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->isic-cli) (2024.2.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from retryable-requests->isic-cli) (1.0.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->isic-cli) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->isic-cli) (2.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->isic-cli) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.4->isic-metadata>=1.2.0->isic-cli) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.4->isic-metadata>=1.2.0->isic-cli) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.4->isic-metadata>=1.2.0->isic-cli) (4.11.0)\n",
            "Requirement already satisfied: cryptography in /usr/lib/python3/dist-packages (from authlib->girder-cli-oauth-client<1.0.0->isic-cli) (3.4.8)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n",
            "Requirement already satisfied: imblearn in /usr/local/lib/python3.10/dist-packages (0.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (from imblearn) (0.12.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (3.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! isic user login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW33o_VNdZdO",
        "outputId": "bb211656-022f-4cc6-c5ce-5d8c7931ebbf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "visit the following url in a browser:\n",
            "https://api.isic-archive.com/oauth/authorize?response_type=code&client_id=RpCzc4hFjv5gOJdM2DM2nBdokOviOh5ne63Tpn7Q&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&state=nHEnl6TM0TFt2mDL0meoaxeqjxZeXt&code_challenge=zqVvw9P1hvPUVYT5UUDxG9NJrwS2Ct3YEutJEW5E9-g&code_challenge_method=S256\n",
            "enter the code shown in your browser: W4vmWFPIAacpcYtd6c4pCKeNf7yiNc\n",
            "Success!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!isic collection list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHkk6C7UfgMk",
        "outputId": "0738cc73-73f2-4116-ba58-26f7b3f747c8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "┏━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1mID \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mName                                         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mPublic\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mPinned\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mLocked\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mDOI            \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
            "│ 249 │ BCN20000                                      │ True   │ False  │ False  │ None            │\n",
            "│ 61  │ Challenge 2016: Test                          │ True   │ True   │ True   │ None            │\n",
            "│ 74  │ Challenge 2016: Training                      │ True   │ True   │ True   │ None            │\n",
            "│ 69  │ Challenge 2017: Test                          │ True   │ True   │ True   │ None            │\n",
            "│ 60  │ Challenge 2017: Training                      │ True   │ True   │ True   │ None            │\n",
            "│ 71  │ Challenge 2017: Validation                    │ True   │ True   │ True   │ None            │\n",
            "│ 64  │ Challenge 2018: Task 1-2: Test                │ True   │ True   │ True   │ None            │\n",
            "│ 63  │ Challenge 2018: Task 1-2: Training            │ True   │ True   │ True   │ None            │\n",
            "│ 62  │ Challenge 2018: Task 1-2: Validation          │ True   │ True   │ True   │ None            │\n",
            "│ 67  │ Challenge 2018: Task 3: Test                  │ True   │ True   │ True   │ None            │\n",
            "│ 66  │ Challenge 2018: Task 3: Training              │ True   │ True   │ True   │ None            │\n",
            "│ 73  │ Challenge 2018: Task 3: Validation            │ True   │ True   │ True   │ None            │\n",
            "│ 65  │ Challenge 2019: Training                      │ True   │ True   │ True   │ None            │\n",
            "│ 70  │ Challenge 2020: Training                      │ True   │ True   │ True   │ None            │\n",
            "│ 97  │ Collection for ISBI 2016: 100 Lesion          │ True   │ False  │ True   │ None            │\n",
            "│     │ Classification                                │        │        │        │                 │\n",
            "│ 216 │ Consecutive biopsies for melanoma across year │ True   │ False  │ True   │ 10.34970/151324 │\n",
            "│     │ 2020                                          │        │        │        │                 │\n",
            "│ 75  │ Consumer AI apps                              │ True   │ False  │ True   │ 10.34970/401946 │\n",
            "│ 166 │ EASY Dermoscopy Expert Agreement Study        │ True   │ False  │ False  │ None            │\n",
            "│ 212 │ HAM10000                                      │ True   │ True   │ True   │ None            │\n",
            "│ 175 │ HIBA Skin Lesions                             │ True   │ False  │ True   │ 10.34970/559884 │\n",
            "│ 251 │ Hospital Italiano de Buenos Aires - Skin      │ True   │ False  │ True   │ 10.34970/587329 │\n",
            "│     │ Lesions Images (2019-2022)                    │        │        │        │                 │\n",
            "│ 176 │ Hospital Italiano de Buenos Aires Skin        │ True   │ False  │ True   │ 10.34970/432362 │\n",
            "│     │ Lesions                                       │        │        │        │                 │\n",
            "│ 217 │ Longitudinal overview images of posterior     │ True   │ False  │ True   │ 10.34970/630662 │\n",
            "│     │ trunks                                        │        │        │        │                 │\n",
            "│ 289 │ MSK-1                                         │ True   │ False  │ True   │ None            │\n",
            "│ 290 │ MSK-2                                         │ True   │ False  │ True   │ None            │\n",
            "│ 288 │ MSK-3                                         │ True   │ False  │ True   │ None            │\n",
            "│ 287 │ MSK-4                                         │ True   │ False  │ True   │ None            │\n",
            "│ 286 │ MSK-5                                         │ True   │ False  │ True   │ None            │\n",
            "│ 163 │ MSKCC Consecutive biopsies across year        │ True   │ False  │ True   │ None            │\n",
            "│     │ 2020_cohort                                   │        │        │        │                 │\n",
            "│ 77  │ Melanocytic lesions used for dermoscopic      │ True   │ False  │ True   │ 10.34970/108631 │\n",
            "│     │ feature annotations                           │        │        │        │                 │\n",
            "│ 294 │ Melanoma and Nevus Dermoscopy Images with     │ True   │ False  │ True   │ 10.34970/277003 │\n",
            "│     │ Confirmed Histopathological Diagnosis         │        │        │        │                 │\n",
            "│ 215 │ Newly-acquired and longer-existing acquired   │ True   │ False  │ True   │ 10.34970/408649 │\n",
            "│     │ melanoma and nevi                             │        │        │        │                 │\n",
            "│ 218 │ PROVe-AI                                      │ True   │ True   │ True   │ 10.34970/576276 │\n",
            "│ 328 │ Repeated Dermoscopic Images of Melanocytic    │ True   │ False  │ True   │ 10.34970/560760 │\n",
            "│     │ Lesions                                       │        │        │        │                 │\n",
            "│ 293 │ SONIC                                         │ True   │ False  │ True   │ None            │\n",
            "│ 292 │ UDA-1                                         │ True   │ False  │ True   │ None            │\n",
            "│ 291 │ UDA-2                                         │ True   │ False  │ True   │ None            │\n",
            "│ 285 │ lesions                                       │ True   │ False  │ False  │ None            │\n",
            "│ 172 │ screenshot_public_230207                      │ True   │ False  │ False  │ None            │\n",
            "└─────┴───────────────────────────────────────────────┴────────┴────────┴────────┴─────────────────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Query the Dataset\n",
        "Endpoints: Use the API endpoints to query the dataset. Common operations include listing available images, retrieving image metadata, and downloading images.\n",
        "Filtering: Utilize query parameters to filter the dataset based on your criteria, such as diagnosis, image type, or other metadata."
      ],
      "metadata": {
        "id": "oonk5DVpQvQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils import resample\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, concatenate, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "Qydcku5hO9JU"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPl5l2XioO78",
        "outputId": "afe551ab-be60-4878-c307-d60711b485b7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment out if already running"
      ],
      "metadata": {
        "id": "2RJkPIfDe5gt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the current path of kaggle.json file\n",
        "current_path = '/content/kaggle.json'\n",
        "\n",
        "# Desired path where the Kaggle API expects the kaggle.json file\n",
        "desired_path = '/root/.kaggle/kaggle.json'\n",
        "\n",
        "if os.path.exists(current_path):\n",
        "    os.makedirs(os.path.dirname(desired_path), exist_ok=True)\n",
        "    os.rename(current_path, desired_path)\n",
        "\n",
        "    # Set the file's permissions to avoid a permissions error\n",
        "    os.chmod(desired_path, 0o600)\n",
        "else:\n",
        "    print(f\"Error: '{current_path}' does not exist. Please upload the file.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "GxvlgkCfxBCt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "find the data set on kaggle\n",
        "\n",
        "Comment out if running and already have downloaded images"
      ],
      "metadata": {
        "id": "MZqQai6mypGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d andrewmvd/isic-2019\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPsM6paiysEU",
        "outputId": "553ea7b5-7002-417e-b11d-e79c8a7eb81d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading isic-2019.zip to /content\n",
            "100% 9.09G/9.10G [01:11<00:00, 140MB/s]\n",
            "100% 9.10G/9.10G [01:11<00:00, 136MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q isic-2019.zip\n"
      ],
      "metadata": {
        "id": "XlWuOA7dyxnf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Data Preparation and Preprocessing\n",
        "DICOM Images\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1_BWFCj4QINb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the metadata\n",
        "\n",
        "and\n",
        "\n",
        "Explore the Metadata CSV: Load the metadata.csv files for training, test, and validation sets to understand the structure and types of data available. This step is crucial for preprocessing and feature selection."
      ],
      "metadata": {
        "id": "BW0CK9GitFSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the metadata\n",
        "metadata = pd.read_csv('/content/ISIC_2019_Training_Metadata.csv')\n",
        "\n",
        "# Display the first few rows of each DataFrame\n",
        "metadata.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "HXZ38h4-2j6e",
        "outputId": "72bc8b25-9334-443f-dab3-78efdf5595c4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          image  age_approx anatom_site_general lesion_id     sex\n",
              "0  ISIC_0000000        55.0      anterior torso       NaN  female\n",
              "1  ISIC_0000001        30.0      anterior torso       NaN  female\n",
              "2  ISIC_0000002        60.0     upper extremity       NaN  female\n",
              "3  ISIC_0000003        30.0     upper extremity       NaN    male\n",
              "4  ISIC_0000004        80.0     posterior torso       NaN    male"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b153078c-502c-4828-ab7c-3b340583c97c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>age_approx</th>\n",
              "      <th>anatom_site_general</th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>sex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ISIC_0000000</td>\n",
              "      <td>55.0</td>\n",
              "      <td>anterior torso</td>\n",
              "      <td>NaN</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ISIC_0000001</td>\n",
              "      <td>30.0</td>\n",
              "      <td>anterior torso</td>\n",
              "      <td>NaN</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ISIC_0000002</td>\n",
              "      <td>60.0</td>\n",
              "      <td>upper extremity</td>\n",
              "      <td>NaN</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ISIC_0000003</td>\n",
              "      <td>30.0</td>\n",
              "      <td>upper extremity</td>\n",
              "      <td>NaN</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ISIC_0000004</td>\n",
              "      <td>80.0</td>\n",
              "      <td>posterior torso</td>\n",
              "      <td>NaN</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b153078c-502c-4828-ab7c-3b340583c97c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b153078c-502c-4828-ab7c-3b340583c97c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b153078c-502c-4828-ab7c-3b340583c97c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5d6f0b5a-f663-4c16-91d0-f15641780593\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5d6f0b5a-f663-4c16-91d0-f15641780593')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5d6f0b5a-f663-4c16-91d0-f15641780593 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "metadata",
              "summary": "{\n  \"name\": \"metadata\",\n  \"rows\": 25331,\n  \"fields\": [\n    {\n      \"column\": \"image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25331,\n        \"samples\": [\n          \"ISIC_0000360\",\n          \"ISIC_0031596\",\n          \"ISIC_0069981\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age_approx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18.130971451746515,\n        \"min\": 0.0,\n        \"max\": 85.0,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          55.0,\n          30.0,\n          70.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"anatom_site_general\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"upper extremity\",\n          \"head/neck\",\n          \"anterior torso\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lesion_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11847,\n        \"samples\": [\n          \"HAM_0004599\",\n          \"HAM_0007480\",\n          \"HAM_0000644\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"male\",\n          \"female\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth = pd.read_csv('/content/ISIC_2019_Training_GroundTruth.csv')\n",
        "ground_truth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "DWo9AD0P5VwB",
        "outputId": "089b3058-3b5f-48e4-a613-de46d5b81581"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              image  MEL   NV  BCC   AK  BKL   DF  VASC  SCC  UNK\n",
              "0      ISIC_0000000  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
              "1      ISIC_0000001  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
              "2      ISIC_0000002  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
              "3      ISIC_0000003  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
              "4      ISIC_0000004  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
              "...             ...  ...  ...  ...  ...  ...  ...   ...  ...  ...\n",
              "25326  ISIC_0073247  0.0  0.0  1.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
              "25327  ISIC_0073248  0.0  0.0  0.0  0.0  1.0  0.0   0.0  0.0  0.0\n",
              "25328  ISIC_0073249  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
              "25329  ISIC_0073251  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
              "25330  ISIC_0073254  0.0  0.0  0.0  0.0  1.0  0.0   0.0  0.0  0.0\n",
              "\n",
              "[25331 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c9b080c7-078a-4d06-b441-0912fb52ae79\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>MEL</th>\n",
              "      <th>NV</th>\n",
              "      <th>BCC</th>\n",
              "      <th>AK</th>\n",
              "      <th>BKL</th>\n",
              "      <th>DF</th>\n",
              "      <th>VASC</th>\n",
              "      <th>SCC</th>\n",
              "      <th>UNK</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ISIC_0000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ISIC_0000001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ISIC_0000002</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ISIC_0000003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ISIC_0000004</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25326</th>\n",
              "      <td>ISIC_0073247</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25327</th>\n",
              "      <td>ISIC_0073248</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25328</th>\n",
              "      <td>ISIC_0073249</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25329</th>\n",
              "      <td>ISIC_0073251</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25330</th>\n",
              "      <td>ISIC_0073254</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25331 rows × 10 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9b080c7-078a-4d06-b441-0912fb52ae79')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c9b080c7-078a-4d06-b441-0912fb52ae79 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c9b080c7-078a-4d06-b441-0912fb52ae79');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2c766de7-8fbd-48a7-ad42-1ed49fee3db0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2c766de7-8fbd-48a7-ad42-1ed49fee3db0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2c766de7-8fbd-48a7-ad42-1ed49fee3db0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_83b9dfe0-7ada-4fa1-baab-2a358b4b7d3e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('ground_truth')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_83b9dfe0-7ada-4fa1-baab-2a358b4b7d3e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('ground_truth');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ground_truth",
              "summary": "{\n  \"name\": \"ground_truth\",\n  \"rows\": 25331,\n  \"fields\": [\n    {\n      \"column\": \"image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25331,\n        \"samples\": [\n          \"ISIC_0000360\",\n          \"ISIC_0031596\",\n          \"ISIC_0069981\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MEL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3829544511327576,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NV\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.49994146244558546,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BCC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33760719760553826,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AK\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1818149205142737,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BKL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.30473197962790843,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0966769248200901,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"VASC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09944041938641913,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SCC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15549302363605394,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"UNK\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hIRZpHWLIVzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV files\n",
        "ground_truth = pd.read_csv('/content/ISIC_2019_Training_GroundTruth.csv')\n",
        "metadata = pd.read_csv('/content/ISIC_2019_Training_Metadata.csv')\n",
        "\n",
        "image_dir = Path('/content/ISIC_2019_Training_Images')\n",
        "ground_truth['image_path'] = ground_truth['image'].apply(lambda x: image_dir / f\"{x}.jpg\")\n",
        "\n",
        "# Merge the ground_truth with metadata if necessary\n",
        "full_metadata = pd.merge(ground_truth, metadata, on='image', how='left')  # Adjust 'on' parameter as needed\n",
        "full_metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "gdODxFjP4Ydi",
        "outputId": "f8c48cdb-1baf-454b-f8f9-6dce2dfe450d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              image  MEL   NV  BCC   AK  BKL   DF  VASC  SCC  UNK  \\\n",
              "0      ISIC_0000000  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   \n",
              "1      ISIC_0000001  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   \n",
              "2      ISIC_0000002  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   \n",
              "3      ISIC_0000003  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   \n",
              "4      ISIC_0000004  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   \n",
              "...             ...  ...  ...  ...  ...  ...  ...   ...  ...  ...   \n",
              "25326  ISIC_0073247  0.0  0.0  1.0  0.0  0.0  0.0   0.0  0.0  0.0   \n",
              "25327  ISIC_0073248  0.0  0.0  0.0  0.0  1.0  0.0   0.0  0.0  0.0   \n",
              "25328  ISIC_0073249  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   \n",
              "25329  ISIC_0073251  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   \n",
              "25330  ISIC_0073254  0.0  0.0  0.0  0.0  1.0  0.0   0.0  0.0  0.0   \n",
              "\n",
              "                                              image_path  age_approx  \\\n",
              "0      /content/ISIC_2019_Training_Images/ISIC_000000...        55.0   \n",
              "1      /content/ISIC_2019_Training_Images/ISIC_000000...        30.0   \n",
              "2      /content/ISIC_2019_Training_Images/ISIC_000000...        60.0   \n",
              "3      /content/ISIC_2019_Training_Images/ISIC_000000...        30.0   \n",
              "4      /content/ISIC_2019_Training_Images/ISIC_000000...        80.0   \n",
              "...                                                  ...         ...   \n",
              "25326  /content/ISIC_2019_Training_Images/ISIC_007324...        85.0   \n",
              "25327  /content/ISIC_2019_Training_Images/ISIC_007324...        65.0   \n",
              "25328  /content/ISIC_2019_Training_Images/ISIC_007324...        70.0   \n",
              "25329  /content/ISIC_2019_Training_Images/ISIC_007325...        55.0   \n",
              "25330  /content/ISIC_2019_Training_Images/ISIC_007325...        50.0   \n",
              "\n",
              "      anatom_site_general    lesion_id     sex  \n",
              "0          anterior torso          NaN  female  \n",
              "1          anterior torso          NaN  female  \n",
              "2         upper extremity          NaN  female  \n",
              "3         upper extremity          NaN    male  \n",
              "4         posterior torso          NaN    male  \n",
              "...                   ...          ...     ...  \n",
              "25326           head/neck  BCN_0003925  female  \n",
              "25327      anterior torso  BCN_0001819    male  \n",
              "25328     lower extremity  BCN_0001085    male  \n",
              "25329         palms/soles  BCN_0002083  female  \n",
              "25330     upper extremity  BCN_0001079    male  \n",
              "\n",
              "[25331 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c7c70639-0b0e-4035-8498-1ed83aeafec6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>MEL</th>\n",
              "      <th>NV</th>\n",
              "      <th>BCC</th>\n",
              "      <th>AK</th>\n",
              "      <th>BKL</th>\n",
              "      <th>DF</th>\n",
              "      <th>VASC</th>\n",
              "      <th>SCC</th>\n",
              "      <th>UNK</th>\n",
              "      <th>image_path</th>\n",
              "      <th>age_approx</th>\n",
              "      <th>anatom_site_general</th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>sex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ISIC_0000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/content/ISIC_2019_Training_Images/ISIC_000000...</td>\n",
              "      <td>55.0</td>\n",
              "      <td>anterior torso</td>\n",
              "      <td>NaN</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ISIC_0000001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/content/ISIC_2019_Training_Images/ISIC_000000...</td>\n",
              "      <td>30.0</td>\n",
              "      <td>anterior torso</td>\n",
              "      <td>NaN</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ISIC_0000002</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/content/ISIC_2019_Training_Images/ISIC_000000...</td>\n",
              "      <td>60.0</td>\n",
              "      <td>upper extremity</td>\n",
              "      <td>NaN</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ISIC_0000003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/content/ISIC_2019_Training_Images/ISIC_000000...</td>\n",
              "      <td>30.0</td>\n",
              "      <td>upper extremity</td>\n",
              "      <td>NaN</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ISIC_0000004</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/content/ISIC_2019_Training_Images/ISIC_000000...</td>\n",
              "      <td>80.0</td>\n",
              "      <td>posterior torso</td>\n",
              "      <td>NaN</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25326</th>\n",
              "      <td>ISIC_0073247</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/content/ISIC_2019_Training_Images/ISIC_007324...</td>\n",
              "      <td>85.0</td>\n",
              "      <td>head/neck</td>\n",
              "      <td>BCN_0003925</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25327</th>\n",
              "      <td>ISIC_0073248</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/content/ISIC_2019_Training_Images/ISIC_007324...</td>\n",
              "      <td>65.0</td>\n",
              "      <td>anterior torso</td>\n",
              "      <td>BCN_0001819</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25328</th>\n",
              "      <td>ISIC_0073249</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/content/ISIC_2019_Training_Images/ISIC_007324...</td>\n",
              "      <td>70.0</td>\n",
              "      <td>lower extremity</td>\n",
              "      <td>BCN_0001085</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25329</th>\n",
              "      <td>ISIC_0073251</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/content/ISIC_2019_Training_Images/ISIC_007325...</td>\n",
              "      <td>55.0</td>\n",
              "      <td>palms/soles</td>\n",
              "      <td>BCN_0002083</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25330</th>\n",
              "      <td>ISIC_0073254</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/content/ISIC_2019_Training_Images/ISIC_007325...</td>\n",
              "      <td>50.0</td>\n",
              "      <td>upper extremity</td>\n",
              "      <td>BCN_0001079</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25331 rows × 15 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7c70639-0b0e-4035-8498-1ed83aeafec6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c7c70639-0b0e-4035-8498-1ed83aeafec6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c7c70639-0b0e-4035-8498-1ed83aeafec6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-41f75a56-3910-4084-8662-9b882e4a8b58\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-41f75a56-3910-4084-8662-9b882e4a8b58')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-41f75a56-3910-4084-8662-9b882e4a8b58 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4122690a-879c-4601-bf85-0d3ff85a034c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('full_metadata')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4122690a-879c-4601-bf85-0d3ff85a034c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('full_metadata');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "full_metadata",
              "summary": "{\n  \"name\": \"full_metadata\",\n  \"rows\": 25331,\n  \"fields\": [\n    {\n      \"column\": \"image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25331,\n        \"samples\": [\n          \"ISIC_0000360\",\n          \"ISIC_0031596\",\n          \"ISIC_0069981\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MEL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3829544511327576,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NV\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.49994146244558546,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BCC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33760719760553826,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AK\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1818149205142737,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BKL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.30473197962790843,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0966769248200901,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"VASC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09944041938641913,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SCC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15549302363605394,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"UNK\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25331,\n        \"samples\": [\n          \"/content/ISIC_2019_Training_Images/ISIC_0000360.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age_approx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18.130971451746515,\n        \"min\": 0.0,\n        \"max\": 85.0,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          55.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"anatom_site_general\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"upper extremity\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lesion_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11847,\n        \"samples\": [\n          \"HAM_0004599\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the image paths for the first few entries\n",
        "print(full_metadata['image_path'].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Bzo5qSzHAk2",
        "outputId": "34250c69-3c7c-46e2-e0a7-fe0c1581d08d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    /content/ISIC_2019_Training_Images/ISIC_000000...\n",
            "1    /content/ISIC_2019_Training_Images/ISIC_000000...\n",
            "2    /content/ISIC_2019_Training_Images/ISIC_000000...\n",
            "3    /content/ISIC_2019_Training_Images/ISIC_000000...\n",
            "4    /content/ISIC_2019_Training_Images/ISIC_000000...\n",
            "Name: image_path, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Correct the base path in 'image_path' column\n",
        "correct_base_path = \"/content/ISIC_2019_Training_Input/ISIC_2019_Training_Input\"\n",
        "\n",
        "full_metadata['image_path'] = full_metadata['image'].apply(lambda x: f\"{correct_base_path}/{x}.jpg\")\n",
        "\n",
        "# Verify the correction by printing the first few entries again\n",
        "print(full_metadata['image_path'].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FDMb1wGHk3d",
        "outputId": "a0dccad1-91c9-407a-bd80-6e222b5975b8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    /content/ISIC_2019_Training_Input/ISIC_2019_Tr...\n",
            "1    /content/ISIC_2019_Training_Input/ISIC_2019_Tr...\n",
            "2    /content/ISIC_2019_Training_Input/ISIC_2019_Tr...\n",
            "3    /content/ISIC_2019_Training_Input/ISIC_2019_Tr...\n",
            "4    /content/ISIC_2019_Training_Input/ISIC_2019_Tr...\n",
            "Name: image_path, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_metadata.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BjtJ7JO9mHO",
        "outputId": "ef187ac1-104d-4cfe-d75b-47290750d6e0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 25331 entries, 0 to 25330\n",
            "Data columns (total 15 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   image                25331 non-null  object \n",
            " 1   MEL                  25331 non-null  float64\n",
            " 2   NV                   25331 non-null  float64\n",
            " 3   BCC                  25331 non-null  float64\n",
            " 4   AK                   25331 non-null  float64\n",
            " 5   BKL                  25331 non-null  float64\n",
            " 6   DF                   25331 non-null  float64\n",
            " 7   VASC                 25331 non-null  float64\n",
            " 8   SCC                  25331 non-null  float64\n",
            " 9   UNK                  25331 non-null  float64\n",
            " 10  image_path           25331 non-null  object \n",
            " 11  age_approx           24894 non-null  float64\n",
            " 12  anatom_site_general  22700 non-null  object \n",
            " 13  lesion_id            23247 non-null  object \n",
            " 14  sex                  24947 non-null  object \n",
            "dtypes: float64(10), object(5)\n",
            "memory usage: 2.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values for 'age_approx' with its median\n",
        "full_metadata['age_approx'].fillna(full_metadata['age_approx'].median(), inplace=True)\n",
        "\n",
        "# For categorical data, fill missing values with 'unknown'\n",
        "full_metadata['anatom_site_general'].fillna('unknown', inplace=True)\n",
        "full_metadata['sex'].fillna('unknown', inplace=True)\n"
      ],
      "metadata": {
        "id": "-W0QskH29_-g"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_metadata = pd.get_dummies(full_metadata, columns=['anatom_site_general', 'sex'])\n"
      ],
      "metadata": {
        "id": "sAeGNqs--IWq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eEWGJgOUprKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of samples per class\n",
        "class_counts = y_train.sum().sort_values(ascending=False)\n",
        "print(\"Class counts before resampling:\\n\", class_counts)\n",
        "\n",
        "# Find the maximum number of samples in any single class\n",
        "max_samples = class_counts.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bP3xzil-prgv",
        "outputId": "4d731e1d-ebd8-4296-fbc4-7e57b507f3d6"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class counts before resampling:\n",
            " NV      10308.0\n",
            "MEL      3607.0\n",
            "BCC      2665.0\n",
            "BKL      2088.0\n",
            "AK        690.0\n",
            "SCC       524.0\n",
            "DF        191.0\n",
            "VASC      191.0\n",
            "UNK         0.0\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting Data into Training, Validation, and Testing Sets\n",
        "\n",
        "The dataset is initially split into training and temporary sets, with the temporary set reserved for further division into validation and test sets. This method ensures that the model can be trained extensively, validated accurately, and finally tested to evaluate its performance on unseen data.\n",
        "\n"
      ],
      "metadata": {
        "id": "uXEBi9lGLVro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Let's separate features and labels first\n",
        "X = full_metadata.drop(['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC', 'UNK'], axis=1)\n",
        "y = full_metadata[['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC']]  # Excluded 'UNK'\n",
        "\n",
        "# Now, we split the data into training and testing sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split the X_temp and y_temp further into validation and test sets\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Calculate the target number of samples\n",
        "target_samples = int((3607 + 10308) / 2)  # adjust this as needed\n",
        "\n",
        "# Create new DataFrame for the balanced dataset\n",
        "X_train_resampled = pd.DataFrame(columns=X_train.columns)\n",
        "y_train_resampled = pd.DataFrame(columns=y_train.columns)\n",
        "\n",
        "# Iterate through each class and apply resampling\n",
        "for column in y_train.columns:\n",
        "    # Filter samples for the current class\n",
        "    filter_mask = y_train[column] == 1\n",
        "    X_class = X_train[filter_mask]\n",
        "    y_class = y_train[filter_mask]\n",
        "\n",
        "    num_samples = len(X_class)\n",
        "    if num_samples > 0:\n",
        "        if num_samples < target_samples:\n",
        "            # Oversample minority classes\n",
        "            X_class_resampled, y_class_resampled = resample(X_class, y_class,\n",
        "                                                            replace=True,  # Sample with replacement\n",
        "                                                            n_samples=target_samples,  # Match the target samples\n",
        "                                                            random_state=42)\n",
        "        else:\n",
        "            # For majority or adequately represented classes, we might undersample or keep as is\n",
        "            X_class_resampled, y_class_resampled = resample(X_class, y_class,\n",
        "                                                            replace=False,\n",
        "                                                            n_samples=target_samples,\n",
        "                                                            random_state=42)\n",
        "\n",
        "        # Append resampled data back to the overall dataset\n",
        "        X_train_resampled = pd.concat([X_train_resampled, X_class_resampled], axis=0)\n",
        "        y_train_resampled = pd.concat([y_train_resampled, y_class_resampled], axis=0)\n",
        "    else:\n",
        "        print(f\"No instances to resample for class '{column}'\")\n",
        "\n",
        "# Shuffle the dataset to mix up class order (important for training)\n",
        "X_train_resampled = X_train_resampled.sample(frac=1, random_state=42)\n",
        "y_train_resampled = y_train_resampled.loc[X_train_resampled.index]\n",
        "\n",
        "print(\"New class counts after resampling:\\n\", y_train_resampled.sum())\n"
      ],
      "metadata": {
        "id": "3xBB1t4rEGjK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f8ca9c5-201b-4abb-f9de-100cfb479ee6"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New class counts after resampling:\n",
            " MEL      20651.0\n",
            "NV        6957.0\n",
            "BCC      25309.0\n",
            "AK       77387.0\n",
            "BKL      30227.0\n",
            "DF      261561.0\n",
            "VASC    261561.0\n",
            "SCC      99679.0\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, y_train.shape)\n",
        "print(X_val.shape, y_val.shape)\n",
        "print(X_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcKsOCJcaFiO",
        "outputId": "48cb0b48-acaf-4c05-e2b2-534d7ac9ea14"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20264, 16) (20264, 9)\n",
            "(2533, 16) (2533, 9)\n",
            "(2534, 16) (2534, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dual Input Data Generator\n",
        "\n",
        "The `DualInputGenerator` class is a custom data generator for handling datasets that include both image paths and associated metadata. It is designed to work with Keras/TensorFlow, enabling efficient batch processing which is crucial for training deep learning models on large datasets. Here's a breakdown of its functionality:\n",
        "\n",
        "- **Initialization (`__init__`)**: This method sets up the generator with all necessary parameters, including image paths, metadata, and labels. It also initializes the batch size, image size, and whether the dataset should be shuffled during training to introduce randomness into the training process.\n",
        "\n",
        "- **Preprocessing (`preprocess_image`)**: A helper function to read and preprocess images. It converts images to the appropriate size and scale ([224x224] in this case) and normalizes pixel values to the range [0, 1].\n",
        "\n",
        "- **Length Calculation (`__len__`)**: This method calculates how many batches are in the dataset, which is used by Keras during training to determine the number of steps per epoch.\n",
        "\n",
        "- **Batch Generation (`__getitem__`)**: This method retrieves a batch of data by processing the images, metadata, and labels. It loads and preprocesses the images specified by the batch indexes, extracts the corresponding metadata, and gathers the labels. The function returns a list containing two arrays (images and metadata) and the batch of labels.\n",
        "\n",
        "- **Epoch End Handling (`on_epoch_end`)**: If shuffling is enabled, this method shuffles the indexes after each epoch to ensure that the model does not see the same sequence of batches every epoch, helping the model to generalize better.\n",
        "\n",
        "This structured approach ensures that the model receives properly formatted and preprocessed data for each training step, facilitating effective learning and performance improvement.\n"
      ],
      "metadata": {
        "id": "lmdnx1WuLlkc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dual Input Generator for creating a mo"
      ],
      "metadata": {
        "id": "86lCVqd8qSaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DualInputGenerator(Sequence):\n",
        "    def __init__(self, image_paths, metadata, labels, batch_size, img_size=(224, 224), shuffle=True):\n",
        "        self.image_paths = image_paths\n",
        "        self.metadata = metadata\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.shuffle = shuffle\n",
        "        self.indexes = np.arange(len(self.image_paths))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def preprocess_image(file_path):\n",
        "      img = tf.io.read_file(file_path)\n",
        "      img = tf.image.decode_jpeg(img, channels=3)\n",
        "      img = tf.image.resize(img, [224, 224])  # Ensuring image size is consistent\n",
        "      img = img / 255.0  # Normalize to [0, 1]\n",
        "      return img\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.image_paths) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      # Calculate start and end indices for the current batch\n",
        "      start_idx = index * self.batch_size\n",
        "      end_idx = (index + 1) * self.batch_size\n",
        "\n",
        "      # Handling last batch which might be smaller than batch_size\n",
        "      end_idx = min(end_idx, len(self.image_paths))\n",
        "\n",
        "      # Batch size might vary for the last batch\n",
        "      current_batch_size = end_idx - start_idx\n",
        "\n",
        "      # Initialize numpy arrays to hold batch data\n",
        "      X_images = np.empty((current_batch_size, *self.img_size, 3))\n",
        "      X_metadata = np.empty((current_batch_size, self.metadata.shape[1]))\n",
        "      y = np.empty((current_batch_size, self.labels.shape[1]), dtype=int)\n",
        "\n",
        "      # Generate data for the current batch\n",
        "      for i, idx in enumerate(range(start_idx, end_idx)):\n",
        "        # Get the image path for current index\n",
        "        img_path = self.image_paths[idx]\n",
        "        img = preprocess_image(img_path)\n",
        "        # Add processed image to the batch\n",
        "        X_images[i, ] = img\n",
        "        # Add corresponding metadata\n",
        "        X_metadata[i, ] = self.metadata[idx]\n",
        "        # Add corresponding label\n",
        "        y[i, ] = self.labels[idx]\n",
        "\n",
        "      return [X_images, X_metadata], y\n",
        "\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n"
      ],
      "metadata": {
        "id": "pP09P7wGBGD3"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initializing Data Generators for Training, Validation, and Testing\n",
        "\n",
        "To ensure our model is trained, validated, and tested with data that is efficiently loaded and preprocessed, we initialize three instances of the `DualInputGenerator` class:\n",
        "\n",
        "- **Training Generator (`train_gen`)**: This generator is configured with training data paths, metadata, and labels. It is responsible for feeding the training data into the model in batches of 32, ensuring that each batch is shuffled to promote model generalization.\n",
        "\n",
        "- **Validation Generator (`val_gen`)**: Similar to the training generator, but using the validation dataset. This generator provides data for evaluating the model during the training process, allowing us to monitor the model's performance and make adjustments if needed without seeing the test data.\n",
        "\n",
        "- **Testing Generator (`test_gen`)**: Finally, the testing generator is set up using the test dataset to evaluate the model's performance after training has been completed. This step is crucial for assessing how well the model is likely to perform on unseen real-world data.\n",
        "\n",
        "Each generator uses the `image_paths`, `metadata`, and `labels` from their respective subsets of the data, ensuring that the model receives all necessary inputs for making predictions during each phase of the training and evaluation process.\n",
        "\n"
      ],
      "metadata": {
        "id": "PmC1R4dDLw7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the training generator\n",
        "train_gen = DualInputGenerator(\n",
        "    image_paths=X_train['image_path'].values,\n",
        "    metadata=X_train.drop(columns=['image', 'image_path', 'lesion_id']).values,\n",
        "    labels=y_train.values,  # Include labels for training set\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# Initialize the validation generator\n",
        "val_gen = DualInputGenerator(\n",
        "    image_paths=X_val['image_path'].values,\n",
        "    metadata=X_val.drop(columns=['image', 'image_path', 'lesion_id']).values,\n",
        "    labels=y_val.values,  # Include labels for validation set\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# Initialize the test generator\n",
        "test_gen = DualInputGenerator(\n",
        "    image_paths=X_test['image_path'].values,\n",
        "    metadata=X_test.drop(columns=['image', 'image_path', 'lesion_id']).values,\n",
        "    labels=y_test.values,  # Include labels for test set\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "X_test['image_path'].values"
      ],
      "metadata": {
        "id": "8gD1J3reWT-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a428d101-5f7b-49f6-997f-b4b5592ebff0"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['/content/ISIC_2019_Training_Input/ISIC_2019_Training_Input/ISIC_0058443.jpg',\n",
              "       '/content/ISIC_2019_Training_Input/ISIC_2019_Training_Input/ISIC_0034027.jpg',\n",
              "       '/content/ISIC_2019_Training_Input/ISIC_2019_Training_Input/ISIC_0034082.jpg',\n",
              "       ...,\n",
              "       '/content/ISIC_2019_Training_Input/ISIC_2019_Training_Input/ISIC_0033029.jpg',\n",
              "       '/content/ISIC_2019_Training_Input/ISIC_2019_Training_Input/ISIC_0027145.jpg',\n",
              "       '/content/ISIC_2019_Training_Input/ISIC_2019_Training_Input/ISIC_0058873.jpg'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dual Input Neural Network Architecture\n",
        "\n",
        "The neural network architecture is designed to handle two types of input: images and metadata. Here's a breakdown of the model architecture and the role of each component:\n",
        "\n",
        "#### Image Input Branch\n",
        "- **Image Input**: The model starts with an image input layer that accepts images of shape (224, 224, 3).\n",
        "- **Convolution and Pooling Layers**: Following the input, the model includes two sets of convolutional layers (`Conv2D`) and max pooling layers (`MaxPooling2D`). Each convolutional layer is followed by batch normalization (`BatchNormalization`), which helps to accelerate the training process and stabilize the learning environment by normalizing the activations.\n",
        "- **Flattening and Dense Layer**: After extracting and pooling features through convolutions, the data is flattened (`Flatten`) and passed through a dense layer with ReLU activation, which is again batch normalized.\n",
        "\n",
        "#### Metadata Input Branch\n",
        "- **Metadata Input**: This branch begins with an input for metadata features, shaped dynamically based on the number of metadata features (`num_metadata_features`).\n",
        "- **Dense Layers and Normalization**: It includes dense layers (`Dense`) with ReLU activation, interspersed with batch normalization to ensure the model learns effectively from the structured data.\n",
        "\n",
        "#### Combining Branches\n",
        "- **Concatenation**: The outputs of the image and metadata branches are combined into a single vector (`concatenate`), allowing the model to learn from both image features and metadata simultaneously.\n",
        "- **Final Dense Layers**: The combined data is then passed through additional dense layers, including a dropout layer (`Dropout`) to prevent overfitting, culminating in a softmax output layer (`Dense`) that classifies the images into one of nine diagnostic categories.\n",
        "\n",
        "#### Model Compilation\n",
        "- The model is compiled with the Adam optimizer, using a learning rate of 1e-4. The loss function used is categorical crossentropy, suitable for multi-class classification tasks, and accuracy is used as the metric to evaluate model performance.\n",
        "\n",
        "This dual-input setup allows the model to leverage both detailed image data and accompanying metadata, aiming to improve diagnostic accuracy compared to using images or metadata alone.\n"
      ],
      "metadata": {
        "id": "Hg7trvZfbOp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_metadata_features = X_train.drop(columns=['image', 'image_path', 'lesion_id']).shape[1]\n",
        "print(\"Number of metadata features:\", num_metadata_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUTOAkX0lHTp",
        "outputId": "41f820c9-0967-4637-ddf6-3667ae4c0081"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of metadata features: 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout, concatenate\n",
        "\n",
        "\n",
        "num_metadata_features = 13\n",
        "\n",
        "\n",
        "# Image input branch\n",
        "image_input = Input(shape=(224, 224, 3), name='image_input')\n",
        "x = Conv2D(32, (3, 3), activation='relu')(image_input)\n",
        "# Add batch normalization here\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "# Add batch normalization here\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Flatten()(x)\n",
        "image_branch = Dense(128, activation='relu')(x)\n",
        "image_branch = BatchNormalization()(image_branch)\n",
        "\n",
        "# Metadata input branch\n",
        "metadata_input = Input(shape=(num_metadata_features,), name='metadata_input')\n",
        "y = Dense(32, activation='relu')(metadata_input)\n",
        "# Normalize after the first dense layer\n",
        "metadata_branch = BatchNormalization()(y)\n",
        "metadata_branch = Dense(64, activation='relu')(metadata_branch)\n",
        "# Normalize before combining\n",
        "metadata_branch = BatchNormalization()(metadata_branch)\n",
        "\n",
        "# Combine the outputs of the two branches\n",
        "combined = concatenate([image_branch, metadata_branch])\n",
        "z = Dense(256, activation='relu')(combined)\n",
        " # Adding dropout for regularization\n",
        "z = Dropout(0.5)(z)\n",
        "# Adjust the number of units to match the number of classes\n",
        "output = Dense(8, activation='softmax')(z)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=[image_input, metadata_input], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "EOCCRKIH6pE3"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Checkpointing Configuration\n",
        "\n",
        "The `ModelCheckpoint` callback in TensorFlow Keras is used to save the model at specific intervals or after achieving certain benchmarks during training. This setup is critical for preserving model states and allows for resuming training without losing previous progress. Here's a detailed explanation of the configuration:\n",
        "\n",
        "- **Checkpoint Path**: Specifies the directory and filename structure for saving the model files. The path includes placeholders for the epoch number (`{epoch:02d}`) and validation accuracy (`{val_accuracy:.2f}`), allowing each file to uniquely represent the state of the model at the end of each epoch.\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "nZwoAjGnmiVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint_path = \"/content/drive/My Drive/your_model_directory/model-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', verbose=3, save_best_only=True, mode='max')"
      ],
      "metadata": {
        "id": "WMPKC0Z4mid1"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SC3rn85NqvsH",
        "outputId": "d35f741b-b2fe-43dc-d4d0-20846fec4717"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TensorFlow Device Placement and Simple Matrix Multiplication\n",
        "\n",
        "To gain insight into how TensorFlow allocates computing resources (such as CPU or GPU) for operations, the `set_log_device_placement` flag is enabled. This setting provides detailed logs showing which devices each operation is assigned to, assisting in debugging and optimizing performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "dGvmgIMCM0LQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.debugging.set_log_device_placement(True)\n",
        "\n",
        "# Test with a simple computation\n",
        "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
        "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
        "# Run on GPU\n",
        "c = tf.matmul(a, b)\n",
        "\n",
        "print(c)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbV-J3q1qz8Q",
        "outputId": "9526ab5a-8038-44e9-8f18-76020c4872b2"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuring Callbacks for Model Training\n",
        "\n",
        "To enhance the training process and ensure optimal model performance, we use a combination of callbacks in TensorFlow. These callbacks are set to monitor the training process and make decisions at the end of each epoch. Here's a breakdown of each callback used:\n",
        "\n",
        "#### EarlyStopping\n",
        "- **Purpose**: Prevents overfitting by halting the training if the model's validation loss does not improve for a specified number of consecutive epochs.\n",
        "- **Configuration**:\n",
        "  - `monitor='val_loss'`: Watches the validation loss metric for changes.\n",
        "  - `patience=2`: Allows the training to continue for 2 epochs without improvements in validation loss.\n",
        "  - `verbose=1`: Enables logging for when the training is stopped early.\n",
        "\n",
        "#### ModelCheckpoint\n",
        "- **Purpose**: Saves the model in its current state after each epoch, but only if the model's performance (based on the monitored metric) has improved.\n",
        "- **Configuration**:\n",
        "  - `filepath='best_model.h5'`: Specifies the location and filename where the best model version will be saved.\n",
        "  - `monitor='val_loss'`: Monitors the validation loss for improvements.\n",
        "  - `save_best_only=True`: Ensures that the model is saved only when its validation loss is at its lowest point seen so far.\n",
        "  - `verbose=1`: Provides detailed logs when the model is saved.\n",
        "\n",
        "These callbacks are essential tools for managing long training sessions effectively. They help conserve resources by stopping training when additional epochs would not lead to improvements (`EarlyStopping`) and by ensuring that only the best model version is saved (`ModelCheckpoint`), thus simplifying deployment and further evaluation.\n"
      ],
      "metadata": {
        "id": "jtj_1lin7bTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=2, verbose=1),\n",
        "    ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "]\n"
      ],
      "metadata": {
        "id": "aMr-5vG72Z98"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the Model\n",
        "#### AND Re-Training, the first model resulted in 70% this is after going back to do futher augmentation\n",
        "\n",
        "To train the dual-input model, we use the `model.fit` method provided by TensorFlow. This method executes the training cycle across a specified number of epochs, allowing for detailed monitoring and adjustments during the training process. Here's a breakdown of each parameter used in the `model.fit` call:\n",
        "\n",
        "- **train_gen**: The training data generator, which supplies batches of image and metadata inputs along with the corresponding labels.\n",
        "- **validation_data**: The validation data generator used to evaluate the model at the end of each epoch, helping monitor its performance on unseen data.\n",
        "- **epochs**: Sets the total number of training cycles the model will undergo. In this case, the model is set to train for 10 epochs.\n",
        "- **steps_per_epoch**: Specifies the number of batch steps to complete one epoch. This is set to the total number of batches available in the training generator (`len(train_gen)`), ensuring that each sample is used once per epoch.\n",
        "- **validation_steps**: Determines the number of batch steps used for validating the model, set to the length of the validation generator.\n",
        "- **callbacks**: Includes the `EarlyStopping` and `ModelCheckpoint` callbacks configured previously. These enhance the training process by:\n",
        "  - **EarlyStopping**: Automatically stops training when the validation loss ceases to decrease, preventing overfitting.\n",
        "  - **ModelCheckpoint**: Saves the best version of the model based on validation loss, ensuring that only the most accurate model is retained.\n",
        "\n",
        "This configuration ensures that the model is not only trained but also validated effectively, with checkpoints saved automatically and training potentially halted early if no further gains are observed. This approach optimizes both the efficiency and efficacy of the model training process.\n",
        "\n"
      ],
      "metadata": {
        "id": "9azv94GqNNcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=10,\n",
        "    steps_per_epoch=len(train_gen),\n",
        "    validation_steps=len(val_gen),\n",
        "    # Include callbacks for early stopping and model checkpointing\n",
        "    callbacks=callbacks\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGXmw8zk2imE",
        "outputId": "6ec519e6-4119-412e-ffd7-ce0ffe8f4e42"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "633/633 [==============================] - ETA: 0s - loss: 1.2916 - accuracy: 0.5634\n",
            "Epoch 1: val_loss improved from inf to 1.03595, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r633/633 [==============================] - 443s 696ms/step - loss: 1.2916 - accuracy: 0.5634 - val_loss: 1.0359 - val_accuracy: 0.6384\n",
            "Epoch 2/10\n",
            "633/633 [==============================] - ETA: 0s - loss: 1.0417 - accuracy: 0.6300\n",
            "Epoch 2: val_loss improved from 1.03595 to 0.97071, saving model to best_model.h5\n",
            "633/633 [==============================] - 436s 688ms/step - loss: 1.0417 - accuracy: 0.6300 - val_loss: 0.9707 - val_accuracy: 0.6622\n",
            "Epoch 3/10\n",
            "633/633 [==============================] - ETA: 0s - loss: 0.9307 - accuracy: 0.6730\n",
            "Epoch 3: val_loss improved from 0.97071 to 0.95731, saving model to best_model.h5\n",
            "633/633 [==============================] - 445s 702ms/step - loss: 0.9307 - accuracy: 0.6730 - val_loss: 0.9573 - val_accuracy: 0.6729\n",
            "Epoch 4/10\n",
            "633/633 [==============================] - ETA: 0s - loss: 0.7874 - accuracy: 0.7221\n",
            "Epoch 4: val_loss improved from 0.95731 to 0.92290, saving model to best_model.h5\n",
            "633/633 [==============================] - 447s 706ms/step - loss: 0.7874 - accuracy: 0.7221 - val_loss: 0.9229 - val_accuracy: 0.6661\n",
            "Epoch 5/10\n",
            "633/633 [==============================] - ETA: 0s - loss: 0.6090 - accuracy: 0.7884\n",
            "Epoch 5: val_loss did not improve from 0.92290\n",
            "633/633 [==============================] - 444s 702ms/step - loss: 0.6090 - accuracy: 0.7884 - val_loss: 0.9758 - val_accuracy: 0.6634\n",
            "Epoch 6/10\n",
            "633/633 [==============================] - ETA: 0s - loss: 0.3850 - accuracy: 0.8766\n",
            "Epoch 6: val_loss did not improve from 0.92290\n",
            "633/633 [==============================] - 443s 700ms/step - loss: 0.3850 - accuracy: 0.8766 - val_loss: 1.1047 - val_accuracy: 0.6511\n",
            "Epoch 6: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_gen, steps=len(test_gen))\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXSsK7n7P0Ke",
        "outputId": "023b7ad6-3d81-40d6-bca4-176af10b4943"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 40s 507ms/step - loss: 1.0843 - accuracy: 0.6511\n",
            "Test Loss: 1.084271788597107\n",
            "Test Accuracy: 0.6511076092720032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "from IPython.display import Image"
      ],
      "metadata": {
        "id": "zw7bRRuLvjHI"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Summary and Visualization\n",
        "\n",
        "The `model.summary()` method outputs a detailed architecture of the model, listing each layer, its type, output shape, and number of parameters. This helps in understanding the depth and complexity of the model's structure. Additionally, the `plot_model` function is used to generate a graphical representation of the model, which includes the shapes and names of each layer, offering a clear visual reference of the model's design.\n",
        "\n",
        "### Generating and Evaluating Predictions\n",
        "\n",
        "After training, predictions are generated for the test set using the `model.predict` method. This function computes the model's output predictions. The `np.argmax` function is then applied to these predictions to convert the model outputs from probabilities to explicit class predictions. This step is crucial for evaluating the model's classification performance on the test data.\n",
        "\n",
        "### Collecting True Classes and Generating Confusion Matrix\n",
        "\n",
        "To evaluate the accuracy of our model's predictions, it is necessary to compare these predicted classes against the true classes from the test set. This comparison is facilitated through the collection of true class labels directly from the test generator. Subsequently, a confusion matrix is generated using the `confusion_matrix` function. This matrix is a powerful tool for visualizing the performance of a classification model, showing the actual versus predicted classifications, which helps in identifying how well the model is performing with respect to different classes. The `seaborn.heatmap` function is then used to plot the confusion matrix, providing a color-coded visualization of the results, which makes it easier to interpret the model's accuracy and misclassifications.\n",
        "\n"
      ],
      "metadata": {
        "id": "z2AWRmDMpZ5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "\n",
        "# Generate a plot of the model\n",
        "plot_model(model, to_file='model_diagram.png', show_shapes=True, show_layer_names=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-j1vR9VcpZGS",
        "outputId": "586940e7-624f-4994-fdc9-ee32f68c8d14"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " image_input (InputLayer)    [(None, 224, 224, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 222, 222, 32)         896       ['image_input[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 222, 222, 32)         128       ['conv2d_11[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPoolin  (None, 111, 111, 32)         0         ['batch_normalization_15[0][0]\n",
            " g2D)                                                               ']                            \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 109, 109, 64)         18496     ['max_pooling2d_8[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 109, 109, 64)         256       ['conv2d_12[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " metadata_input (InputLayer  [(None, 13)]                 0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_9 (MaxPoolin  (None, 54, 54, 64)           0         ['batch_normalization_16[0][0]\n",
            " g2D)                                                               ']                            \n",
            "                                                                                                  \n",
            " dense_21 (Dense)            (None, 32)                   448       ['metadata_input[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_4 (Flatten)         (None, 186624)               0         ['max_pooling2d_9[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 32)                   128       ['dense_21[0][0]']            \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_20 (Dense)            (None, 128)                  2388800   ['flatten_4[0][0]']           \n",
            "                                                          0                                       \n",
            "                                                                                                  \n",
            " dense_22 (Dense)            (None, 64)                   2112      ['batch_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 128)                  512       ['dense_20[0][0]']            \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_19 (Ba  (None, 64)                   256       ['dense_22[0][0]']            \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate  (None, 192)                  0         ['batch_normalization_17[0][0]\n",
            " )                                                                  ',                            \n",
            "                                                                     'batch_normalization_19[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_23 (Dense)            (None, 256)                  49408     ['concatenate_4[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 256)                  0         ['dense_23[0][0]']            \n",
            "                                                                                                  \n",
            " dense_24 (Dense)            (None, 8)                    2056      ['dropout_4[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23962696 (91.41 MB)\n",
            "Trainable params: 23962056 (91.41 MB)\n",
            "Non-trainable params: 640 (2.50 KB)\n",
            "__________________________________________________________________________________________________\n",
            "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions using the test generator\n",
        "predictions = model.predict(test_gen, steps=len(test_gen))\n",
        "\n",
        "# Obtain the predicted classes by taking the argmax of the predictions array\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Since your test_gen should also be outputting the true classes in the same order as the predictions:\n",
        "# We need to collect all true classes from the generator (in the same order)\n",
        "true_classes = []\n",
        "for _, labels in test_gen:\n",
        "    true_classes.extend(np.argmax(labels, axis=1))\n",
        "    if len(true_classes) >= len(predictions):\n",
        "        break  # Stop once we have all the labels we need\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(true_classes[:len(predictions)], predicted_classes)\n",
        "\n",
        "print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "f0trS3wm7Vdn",
        "outputId": "71aee734-1cf8-4434-9882-440bbfab3f40"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "local variable 'img_path' referenced before assignment",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-b318e5f11ada>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Generate predictions using the test generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Obtain the predicted classes by taking the argmax of the predictions array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredicted_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-69-9f3b77835bdf>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mX_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Generate data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'img_path' referenced before assignment"
          ]
        }
      ]
    },
    {
      "source": [
        "# Generate predictions using the test generator\n",
        "predictions = model.predict(test_gen, steps=len(test_gen))\n",
        "\n",
        "# Obtain the predicted classes by taking the argmax of the predictions array\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Since your test_gen should also be outputting the true classes in the same order as the predictions:\n",
        "# We need to collect all true classes from the generator (in the same order)\n",
        "true_classes = []\n",
        "for _, labels in test_gen:\n",
        "    true_classes.extend(np.argmax(labels, axis=1))\n",
        "    if len(true_classes) >= len(predictions):\n",
        "        break  # Stop once we have all the labels we need\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(true_classes[:len(predictions)], predicted_classes)\n",
        "\n",
        "print(cm)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "o0zNgkl56J9_",
        "outputId": "c60cc8e4-08dc-4ad0-bc21-1328b67a508b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/79 [======>.......................] - ETA: 30s"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4zTsYozZ7XKz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "outputId": "965a42d2-d35f-4ab6-f1da-6475590f7d68"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Summary of Confusin Matrix\n",
        "Classes 3, 4, 5, 6, and 7 show a particular need for augmentation due to low true positives and high confusion with other classes. Class 0 also needs attention due to being frequently confused with other high-incidence classes. These focused augmentations aim to enhance the model's ability to distinguish these classes more clearly, which should improve overall accuracy and reduce misclassifications."
      ],
      "metadata": {
        "id": "NTCa0XIjR5TF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "66.46% is ok, but lets do some fine tuning... and save it!\n",
        "\n",
        "### Model Evaluation and Misclassification Analysis\n",
        "\n",
        "The process starts by loading a previously trained model from disk using `load_model`. This model is then used to evaluate its performance on unseen data provided by a test generator. The evaluation consists of several steps:\n",
        "\n",
        "#### Loading the Model\n",
        "The model is loaded from a saved file, ensuring that the most effective version of the model, as determined by prior validations, is used for evaluations.\n",
        "\n",
        "#### Fetching Predictions and Labels\n",
        "A custom function `get_predictions_and_labels` is employed to iterate over the test generator. This function fetches batches of data (both images and metadata) and corresponding labels, then uses the model to predict each batch. Predictions and true labels are accumulated from all batches, allowing for comprehensive evaluation.\n",
        "\n",
        "#### Calculating Confusion Matrix and Classification Report\n",
        "Once predictions are gathered, they are converted from softmax probabilities to class predictions using `np.argmax`. With predictions and true labels in hand, a confusion matrix is generated to visually assess the model's performance across different classes. This matrix highlights which classes are being confused with others, providing insight into potential biases or weaknesses in the model.\n",
        "\n",
        "A classification report is also generated to provide key metrics for each class, such as precision, recall, and F1-score. This report helps in understanding the model's accuracy and identifying classes that might require more focus during further model training.\n",
        "\n",
        "#### Visualizing Misclassified Examples\n",
        "Finally, the script identifies and displays a set of misclassified images along with their true and predicted labels. This visualization is crucial for diagnosing what might be causing the errors, potentially guiding further data collection, augmentation strategies, or model adjustments.\n",
        "\n",
        "Each of these steps plays a vital role in evaluating the model's real-world applicability and robustness, ensuring that the model not only performs well statistically but also meets practical expectations.\n"
      ],
      "metadata": {
        "id": "e4WEe_Pe4GPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the model\n",
        "model = load_model('/content/best_model.h5')\n",
        "\n",
        "# Function to fetch data and labels from the generator\n",
        "def get_predictions_and_labels(generator):\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "    for _ in range(len(generator)):\n",
        "        # Getting the next batch of data\n",
        "        (images, metadata), labels = generator.__getitem__(_)\n",
        "        # Predict this batch\n",
        "        batch_predictions = model.predict([images, metadata])\n",
        "        # Store predictions and labels\n",
        "        predictions.append(batch_predictions)\n",
        "        true_labels.append(labels)\n",
        "\n",
        "    # Concatenate all batches\n",
        "    predictions = np.vstack(predictions)\n",
        "    true_labels = np.vstack(true_labels)\n",
        "\n",
        "    return predictions, true_labels\n",
        "\n",
        "# Using the test generator to get predictions and labels\n",
        "predictions, true_labels = get_predictions_and_labels(test_gen)\n",
        "\n",
        "# Convert softmax probabilities to class predictions\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "true_classes = np.argmax(true_labels, axis=1)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(true_classes, predicted_classes)\n",
        "print('Confusion Matrix:\\n', cm)\n",
        "\n",
        "# Generate a classification report\n",
        "print('\\nClassification Report:\\n', classification_report(true_classes, predicted_classes))\n",
        "\n",
        "# Identify misclassified examples\n",
        "misclassified_indices = np.where(predicted_classes != true_classes)[0]\n",
        "print(f'Total misclassified samples: {len(misclassified_indices)}')\n",
        "\n",
        "# Assuming you want to visualize some misclassified images:\n",
        "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(10, 10))\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "    if i < len(misclassified_indices):\n",
        "        idx = misclassified_indices[i]\n",
        "        img = test_gen.image_paths[idx]  # Assuming image paths are stored here\n",
        "        true_label, pred_label = true_classes[idx], predicted_classes[idx]\n",
        "        ax.imshow(plt.imread(img))  # Reading the image from path\n",
        "        ax.set_title(f'True: {true_label}, Pred: {pred_label}')\n",
        "        ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "N7xEntx2yeYI",
        "outputId": "fec9f680-d3fc-49e7-f2ff-47853baee063"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "local variable 'img_path' referenced before assignment",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-d4825e3d9db1>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Using the test generator to get predictions and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_predictions_and_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Convert softmax probabilities to class predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-83-d4825e3d9db1>\u001b[0m in \u001b[0;36mget_predictions_and_labels\u001b[0;34m(generator)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Getting the next batch of data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Predict this batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mbatch_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-69-9f3b77835bdf>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mX_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Generate data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'img_path' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets just run it a few more times and see if it can get any better before it gets any worse..."
      ],
      "metadata": {
        "id": "4kQ7HYQITe-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Load the previously saved model\n",
        "model = load_model('/content/best_model.h5')\n",
        "\n",
        "# Define your callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=2, verbose=1),\n",
        "    ModelCheckpoint(filepath='/content/best_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "]\n",
        "\n",
        "# Path where the checkpoint will be saved\n",
        "model_dir = '/content/drive/My Drive/Colab Models'\n",
        "# Generate a unique identifier based on the current date and time\n",
        "unique_identifier = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "checkpoint_filepath = os.path.join(model_dir, f'best_model_{unique_identifier}.h5')\n",
        "\n",
        "# model_filename = 'best_model.h5'\n",
        "# # Check if the best model exists and load it\n",
        "# if os.path.exists(model_filename):\n",
        "#     model = load_model(model_filename)\n",
        "#     print(\"Loaded the best model from the last training session.\")\n",
        "# # Continue with defining callbacks without overwriting the best model inadvertently\n",
        "# # callbacks = [\n",
        "# #    ModelCheckpoint(filepath=model_filename, monitor='val_loss', save_best_only=True, verbose=1)]\n",
        "\n",
        "\n",
        "# Continue training with generators and include callbacks\n",
        "history2 = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    # Adjust the total epochs as needed\n",
        "    epochs=20,\n",
        "    steps_per_epoch=len(train_gen),\n",
        "    validation_steps=len(val_gen),\n",
        "    callbacks=callbacks\n",
        ")\n"
      ],
      "metadata": {
        "id": "BstjOq4WvTz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation of Classifier Performance Using ROC Curves\n",
        "\n",
        "To evaluate the performance of the classifier on a per-class basis, the Receiver Operating Characteristic (ROC) curves and the Area Under the Curve (AUC) are computed. These metrics are crucial for assessing the model's ability to distinguish between classes. Here's a breakdown of the steps involved in this evaluation:\n",
        "\n",
        "#### Preparing Labels and Predictions\n",
        "Firstly, the true labels are converted to a 1-dimensional array if they are not already in this format, ensuring they can be directly compared with the predicted probabilities. Predictions are checked to ensure they contain a probability for each class.\n",
        "\n",
        "#### Computing ROC Curves and AUC Values\n",
        "For each class, the ROC curve is calculated by:\n",
        "- Isolating the prediction probabilities for that class.\n",
        "- Creating a binary outcome array for the class, where the class of interest is labeled `1` and all others `0`.\n",
        "- Using the `roc_curve` function from `sklearn.metrics` to compute the true positive rate (TPR) and false positive rate (FPR) at various threshold settings.\n",
        "- Calculating the AUC value to quantify the overall ability of the model to discriminate between positive and negative classes for each specific class.\n",
        "\n",
        "#### Plotting the ROC Curves\n",
        "Each class's ROC curve is plotted with a unique color, and the AUC score is displayed in the legend to provide a visual and numerical representation of classifier performance. The diagonal line represents a random classifier's performance for comparison.\n",
        "\n",
        "- **X-axis**: False Positive Rate (FPR) — represents the proportion of negative data points that are mistakenly considered positive.\n",
        "- **Y-axis**: True Positive Rate (TPR) — represents the proportion of actual positives correctly identified.\n",
        "\n",
        "The area under each curve (AUC) provides a single measure of overall performance regardless of the classification threshold. The closer the AUC is to 1, the better the model is at predicting positive classes as positive and negative classes as negative. Values closer to 0.5 suggest no discriminative ability, equivalent to random guessing.\n",
        "\n",
        "This detailed analysis helps in identifying which classes the model performs well on and which ones might require further tuning, potentially guiding further data augmentation, additional training, or algorithm adjustments.\n"
      ],
      "metadata": {
        "id": "_WhYhVOuPPKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ensure that true_labels is a 1D array of class indices\n",
        "if len(true_labels.shape) > 1:\n",
        "    true_labels = np.argmax(true_labels, axis=1)\n",
        "\n",
        "# Ensure predictions are probabilities\n",
        "if predictions.shape[1] == len(np.unique(true_labels)):\n",
        "    print(\"Predictions appear to be properly formatted.\")\n",
        "\n",
        "n_classes = len(np.unique(true_labels))\n",
        "fpr = {}\n",
        "tpr = {}\n",
        "roc_auc = {}\n",
        "\n",
        "for i in range(n_classes):\n",
        "    # Isolate the probabilities for the current class\n",
        "    class_probs = predictions[:, i]\n",
        "    # Create a binary outcome for this class\n",
        "    class_true = (true_labels == i).astype(int)\n",
        "    fpr[i], tpr[i], _ = roc_curve(class_true, class_probs)\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plot ROC curves\n",
        "plt.figure(figsize=(10, 8))\n",
        "colors = plt.cm.viridis(np.linspace(0, 1, n_classes))\n",
        "for i in range(n_classes):\n",
        "    plt.plot(fpr[i], tpr[i], color=colors[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve by class')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "MXn21DHQ1Oca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_gen, steps=len(test_gen))\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "id": "jYDZeSsKEWjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **The Interface** ⚡\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "fCM0RYQ6fov0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "User Interface (UI)\n",
        "A simple web-based UI allows users to upload lesion images, input relevant metadata, and receive a prediction. We will use Gradio as learned in class for this model."
      ],
      "metadata": {
        "id": "Y_b53V90Dlbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install gradio --upgrade\n",
        "! pip install gradio ai"
      ],
      "metadata": {
        "id": "iZPbWw523sBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install openai"
      ],
      "metadata": {
        "id": "AfbMqU7FILRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from gradio import Image, Number, Radio, Dropdown\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "from PIL import Image as PILImage\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import openai"
      ],
      "metadata": {
        "id": "vJ11PNQbghbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/API AI OPEN.txt', 'r') as file:\n",
        "    openai_api_key = file.read().strip()"
      ],
      "metadata": {
        "id": "hqA1v6buyrjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = openai_api_key"
      ],
      "metadata": {
        "id": "ffJ-dau384GW"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Loading and Prediction Testing\n",
        "\n",
        "#### Loading the Pre-trained Model\n",
        "The script begins by loading a pre-trained model from a specified path. This model is essential for predicting the type of skin lesions based on image data and associated metadata.\n",
        "\n",
        "#### Model Architecture Overview\n",
        "Once the model is loaded, `model.summary()` is called to print the architecture of the model. This summary provides insight into the model's layers, their shapes, and parameters, which is crucial for understanding how the model processes input data.\n",
        "\n",
        "#### Dummy Prediction\n",
        "To ensure the model is functioning correctly, a dummy input array is created using random data, shaped appropriately for the model's expected input (in this case, 224x224x3 for image data). This array is then used to make a prediction, testing the model's readiness for actual data.\n",
        "\n",
        "### Image Preprocessing and Prediction Explanation Function\n",
        "\n",
        "#### Image Preprocessing\n",
        "The script defines a function `preprocess_image` that takes an uploaded image file, resizes it to fit the model's input requirements, normalizes the pixel values, and expands its dimensions to include a batch size for model input compatibility.\n",
        "\n",
        "#### Prediction and Explanation Generation\n",
        "Another function, `predict_and_explain`, is designed to handle the end-to-end process from image and metadata input through to generating a human-readable explanation of the prediction. This function:\n",
        "- Preprocesses the input image for model prediction.\n",
        "- Uses the model to predict the lesion type based on the image.\n",
        "- Maps the prediction to a readable class description.\n",
        "- Optionally, uses GPT-3 to generate a detailed explanation of the diagnosis, integrating the lesion's metadata for a comprehensive overview.\n",
        "\n",
        "### User Interface for Skin Lesion Classification\n",
        "\n",
        "#### Interface Setup\n",
        "The script utilizes `gr.Interface` from the Gradio library to create an interactive web interface. This interface allows users to upload images of skin lesions and input relevant metadata (age, sex, and anatomical site).\n",
        "\n",
        "#### Interface Launch\n",
        "Finally, the interface is launched, making it accessible via a web browser. Users can interact with the model, upload images, input metadata, and receive predictions along with explanations right in the interface.\n",
        "\n",
        "### Usage and Disclaimer\n",
        "The interface includes a title and a detailed description, advising users on how to use the tool and noting that predictions should not replace professional medical advice. This ensures users understand the context and limitations of the model predictions.\n",
        "\n",
        "This comprehensive setup allows for an accessible and user-friendly way to leverage advanced machine learning models for educational and preliminary diagnostic support in dermatology.\n"
      ],
      "metadata": {
        "id": "zsqTPa3RhUkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diagnosis_descriptions = {\n",
        "    'MEL': 'Melanoma: a serious form of skin cancer that begins in cells known as melanocytes.',\n",
        "    'NV': 'Melanocytic nevus: a common type of skin growth that often appears as a small, dark brown spot.',\n",
        "    'BCC': 'Basal cell carcinoma: a type of skin cancer that most often develops on areas exposed to the sun.',\n",
        "    'AK': 'Actinic keratosis: a rough, scaly patch on the skin caused by years of sun exposure.',\n",
        "    'BKL': 'Benign keratosis: a non-cancerous skin condition that appears as a waxy brown, black, or tan growth.',\n",
        "    'DF': 'Dermatofibroma: a common growth on the skin, usually found on the lower legs, that can be pink, red, or brown.',\n",
        "    'VASC': 'Vascular lesion: a type of abnormal growth or mark on the skin that is made up of blood vessels.',\n",
        "    'SCC': 'Squamous cell carcinoma: a common form of skin cancer that develops in the squamous cells.',\n",
        "    'UNK': 'None of the others: the lesion does not fit into any of the other categories.'\n",
        "}\n",
        "\n",
        "disclaimer = \"\"\"\n",
        "**Disclaimer:** This tool is intended for educational and entertainment purposes only and should not be used as a substitute for professional medical advice, diagnosis, or treatment. Always seek the advice of your physician or other qualified health provider with any questions you may have regarding a medical condition. Remember, this AI is not a medical doctor, and its assessments are not diagnoses. Use this tool responsibly and always consult with a healthcare professional for any medical concerns.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "M3H3C8nki6Hl"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "model_path = '/content/best_model.h5'\n",
        "model = keras.models.load_model(model_path)\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "\n",
        "# Create a dummy input array for metadata\n",
        "test_metadata = np.random.random((1, 13))  # Assuming metadata has shape (1, 13)\n",
        "\n",
        "# Combine image data and metadata\n",
        "test_input_image = np.random.random((1, 224, 224, 3))  # Assuming image data has shape (1, 224, 224, 3)\n",
        "test_input = [test_input_image, test_metadata]\n",
        "\n",
        "# Make a prediction\n",
        "test_prediction = model.predict(test_input)\n",
        "print(test_prediction)\n",
        "\n",
        "def preprocess_image(uploaded_image):\n",
        "    img = PILImage.open(uploaded_image).resize((224, 224))  # Ensure uploaded_image is a path or file-like object\n",
        "    img_array = np.array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return img_array\n",
        "\n",
        "def predict_and_explain(image, metadata):\n",
        "    preprocessed_image = preprocess_image(image)\n",
        "    # Extract metadata features\n",
        "    metadata_array = np.array(metadata)\n",
        "\n",
        "    # Pass inputs as a single list to the predict function\n",
        "    prediction = model.predict([preprocessed_image, metadata_array])[0]\n",
        "    predicted_class_index = np.argmax(prediction)\n",
        "    predicted_class_key = list(diagnosis_descriptions.keys())[predicted_class_index]\n",
        "    description = diagnosis_descriptions[predicted_class_key]\n",
        "\n",
        "    metadata_sentence = f\"A {metadata['age']}-year-old {metadata['sex']} has a lesion located at {metadata['location']}.\"\n",
        "\n",
        "    try:\n",
        "        response = openai.Completion.create(\n",
        "            engine=\"text-davinci-003\",\n",
        "            prompt=f\"{metadata_sentence} It was diagnosed as {predicted_class_key} ({description}). Provide an explanation.\",\n",
        "            temperature=0.7,\n",
        "            max_tokens=100\n",
        "        )\n",
        "        additional_info = response.choices[0].text.strip()\n",
        "    except Exception as e:\n",
        "        additional_info = \"Could not fetch additional information from GPT-3.\"\n",
        "\n",
        "    full_explanation = f\"Diagnosis: {predicted_class_key} - {description}.\\n\\nAdditional info: {additional_info}\"\n",
        "    return full_explanation\n",
        "\n",
        "# Create the interface\n",
        "iface = gr.Interface(\n",
        "    fn=predict_and_explain,\n",
        "    inputs=[\n",
        "        Image(),  # Removed the shape parameter\n",
        "        Number(label=\"Age\"),\n",
        "        Radio(choices=['Male', 'Female', 'Other'], label=\"Sex\"),\n",
        "        Dropdown(choices=['Head/Neck', 'Upper Extremity', 'Lower Extremity', 'Torso', 'Palms/Soles', 'Oral/Genital', 'Other'], label=\"Anatomical Site\")\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    title=\"Skin Lesion Classifier\",\n",
        "    description=\"Upload an image of a skin lesion and enter metadata to predict its type. Read the disclaimer below before proceeding.\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch(debug=True)\n"
      ],
      "metadata": {
        "id": "JVanQA1QKvHA",
        "outputId": "331288da-470d-42e8-fbc1-531471cdea62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " image_input (InputLayer)    [(None, 224, 224, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 222, 222, 32)         896       ['image_input[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 111, 111, 32)         0         ['conv2d[0][0]']              \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 109, 109, 64)         18496     ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 54, 54, 64)           0         ['conv2d_1[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " metadata_input (InputLayer  [(None, 13)]                 0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 186624)               0         ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 32)                   448       ['metadata_input[0][0]']      \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 128)                  2388800   ['flatten[0][0]']             \n",
            "                                                          0                                       \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 64)                   2112      ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 192)                  0         ['dense[0][0]',               \n",
            "                                                                     'dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 256)                  49408     ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 256)                  0         ['dense_3[0][0]']             \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 9)                    2313      ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23961673 (91.41 MB)\n",
            "Trainable params: 23961673 (91.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "[[2.1788788e-08 9.3542242e-01 6.8698385e-09 1.2977195e-08 6.4577274e-02\n",
            "  3.0174081e-07 8.1468104e-10 2.4654501e-15 4.8618424e-22]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No image data found. Expecting filename, url, or data.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-bb4800f0b20a>\u001b[0m in \u001b[0;36m<cell line: 53>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict_and_explain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     inputs=[\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Removed the shape parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mNumber\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Age\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mRadio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Male'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Female'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Other'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Sex\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_ext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1187\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No image data found. Expecting filename, url, or data.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1188\u001b[0m         elif isinstance(data, str) and (\n\u001b[1;32m   1189\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_safe_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No image data found. Expecting filename, url, or data."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MoCRCPohKmjb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}