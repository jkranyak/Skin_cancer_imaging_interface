{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://github.com/jkranyak/project_3/blob/main/project3.ipynb",
      "authorship_tag": "ABX9TyOA0zKTGeMKUHXa49RBtcRI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jkranyak/project_3/blob/main/project3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTn88MrjoCyu",
        "outputId": "740bf6e6-80c8-47a5-db9c-45b835aa5374"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Apr 10 20:29:25 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9dKgTXpPs_K",
        "outputId": "172e3f01-7380-4757-9222-eeba4e66db58"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install isic-cli\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVVKoI12Psz6",
        "outputId": "4ea6fe4e-51b0-479c-ea56-bbfc82f487ae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting isic-cli\n",
            "  Downloading isic_cli-10.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: click>=8 in /usr/local/lib/python3.10/dist-packages (from isic-cli) (8.1.7)\n",
            "Collecting django-s3-file-field-client>=1.0.0 (from isic-cli)\n",
            "  Downloading django_s3_file_field_client-1.0.1-py3-none-any.whl (3.2 kB)\n",
            "Collecting girder-cli-oauth-client<1.0.0 (from isic-cli)\n",
            "  Downloading girder_cli_oauth_client-0.4.0-py3-none-any.whl (8.1 kB)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from isic-cli) (4.7.0)\n",
            "Collecting isic-metadata>=1.2.0 (from isic-cli)\n",
            "  Downloading isic_metadata-1.5.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from isic-cli) (10.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from isic-cli) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from isic-cli) (2.31.0)\n",
            "Collecting retryable-requests (from isic-cli)\n",
            "  Downloading retryable_requests-0.1.2-py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from isic-cli) (13.7.1)\n",
            "Collecting sentry-sdk (from isic-cli)\n",
            "  Downloading sentry_sdk-1.45.0-py2.py3-none-any.whl (267 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.1/267.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (from isic-cli) (8.2.3)\n",
            "Collecting authlib (from girder-cli-oauth-client<1.0.0->isic-cli)\n",
            "  Downloading Authlib-1.3.0-py2.py3-none-any.whl (223 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.7/223.7 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyxdg (from girder-cli-oauth-client<1.0.0->isic-cli)\n",
            "  Downloading pyxdg-0.28-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=2.4 in /usr/local/lib/python3.10/dist-packages (from isic-metadata>=1.2.0->isic-cli) (2.6.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->isic-cli) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->isic-cli) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->isic-cli) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->isic-cli) (2024.2.2)\n",
            "Collecting requests-toolbelt (from retryable-requests->isic-cli)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->isic-cli) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->isic-cli) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->isic-cli) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.4->isic-metadata>=1.2.0->isic-cli) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.4->isic-metadata>=1.2.0->isic-cli) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.4->isic-metadata>=1.2.0->isic-cli) (4.10.0)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.10/dist-packages (from authlib->girder-cli-oauth-client<1.0.0->isic-cli) (42.0.5)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography->authlib->girder-cli-oauth-client<1.0.0->isic-cli) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography->authlib->girder-cli-oauth-client<1.0.0->isic-cli) (2.22)\n",
            "Installing collected packages: pyxdg, sentry-sdk, requests-toolbelt, django-s3-file-field-client, retryable-requests, isic-metadata, authlib, girder-cli-oauth-client, isic-cli\n",
            "Successfully installed authlib-1.3.0 django-s3-file-field-client-1.0.1 girder-cli-oauth-client-0.4.0 isic-cli-10.0.0 isic-metadata-1.5.0 pyxdg-0.28 requests-toolbelt-1.0.0 retryable-requests-0.1.2 sentry-sdk-1.45.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! isic user login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW33o_VNdZdO",
        "outputId": "a4aeee57-a962-420e-e909-bfa905895c19"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "visit the following url in a browser:\n",
            "https://api.isic-archive.com/oauth/authorize?response_type=code&client_id=RpCzc4hFjv5gOJdM2DM2nBdokOviOh5ne63Tpn7Q&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&state=kmGwfoz4avuEVKECGVadANUQxs5Q1D&code_challenge=wNZcxvZUgcaMlKSwsGU8BhZt_yqDd7JTA6dVzC5JrW0&code_challenge_method=S256\n",
            "enter the code shown in your browser: 8feAFBcQvyoeNl9BDi5Kjx00Or6x3D\n",
            "Success!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Query the Dataset\n",
        "Endpoints: Use the API endpoints to query the dataset. Common operations include listing available images, retrieving image metadata, and downloading images.\n",
        "Filtering: Utilize query parameters to filter the dataset based on your criteria, such as diagnosis, image type, or other metadata."
      ],
      "metadata": {
        "id": "oonk5DVpQvQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install isic-cli\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8BVrTm2Svw1",
        "outputId": "26744169-1c63-47ea-ab9f-2111c43d981a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: isic-cli in /usr/local/lib/python3.10/dist-packages (10.0.0)\n",
            "Requirement already satisfied: click>=8 in /usr/local/lib/python3.10/dist-packages (from isic-cli) (8.1.7)\n",
            "Requirement already satisfied: django-s3-file-field-client>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from isic-cli) (1.0.1)\n",
            "Requirement already satisfied: girder-cli-oauth-client<1.0.0 in /usr/local/lib/python3.10/dist-packages (from isic-cli) (0.4.0)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from isic-cli) (4.7.0)\n",
            "Requirement already satisfied: isic-metadata>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from isic-cli) (1.5.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from isic-cli) (10.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from isic-cli) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from isic-cli) (2.31.0)\n",
            "Requirement already satisfied: retryable-requests in /usr/local/lib/python3.10/dist-packages (from isic-cli) (0.1.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from isic-cli) (13.7.1)\n",
            "Requirement already satisfied: sentry-sdk in /usr/local/lib/python3.10/dist-packages (from isic-cli) (1.45.0)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (from isic-cli) (8.2.3)\n",
            "Requirement already satisfied: authlib in /usr/local/lib/python3.10/dist-packages (from girder-cli-oauth-client<1.0.0->isic-cli) (1.3.0)\n",
            "Requirement already satisfied: pyxdg in /usr/local/lib/python3.10/dist-packages (from girder-cli-oauth-client<1.0.0->isic-cli) (0.28)\n",
            "Requirement already satisfied: pydantic>=2.4 in /usr/local/lib/python3.10/dist-packages (from isic-metadata>=1.2.0->isic-cli) (2.6.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->isic-cli) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->isic-cli) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->isic-cli) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->isic-cli) (2024.2.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from retryable-requests->isic-cli) (1.0.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->isic-cli) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->isic-cli) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->isic-cli) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.4->isic-metadata>=1.2.0->isic-cli) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.4->isic-metadata>=1.2.0->isic-cli) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.4->isic-metadata>=1.2.0->isic-cli) (4.10.0)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.10/dist-packages (from authlib->girder-cli-oauth-client<1.0.0->isic-cli) (42.0.5)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography->authlib->girder-cli-oauth-client<1.0.0->isic-cli) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography->authlib->girder-cli-oauth-client<1.0.0->isic-cli) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Op1vr6L2xHQj",
        "outputId": "5bbc8cdf-37ce-4975-eb84-21e68515720f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!isic collection list\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kk68cVPmStBo",
        "outputId": "6a61e1fd-5522-4bff-91f0-561eb3cb4998"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "┏━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1mID \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mName                                         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mPublic\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mPinned\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mLocked\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mDOI            \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
            "│ 249 │ BCN20000                                      │ True   │ False  │ False  │ None            │\n",
            "│ 61  │ Challenge 2016: Test                          │ True   │ True   │ True   │ None            │\n",
            "│ 74  │ Challenge 2016: Training                      │ True   │ True   │ True   │ None            │\n",
            "│ 69  │ Challenge 2017: Test                          │ True   │ True   │ True   │ None            │\n",
            "│ 60  │ Challenge 2017: Training                      │ True   │ True   │ True   │ None            │\n",
            "│ 71  │ Challenge 2017: Validation                    │ True   │ True   │ True   │ None            │\n",
            "│ 64  │ Challenge 2018: Task 1-2: Test                │ True   │ True   │ True   │ None            │\n",
            "│ 63  │ Challenge 2018: Task 1-2: Training            │ True   │ True   │ True   │ None            │\n",
            "│ 62  │ Challenge 2018: Task 1-2: Validation          │ True   │ True   │ True   │ None            │\n",
            "│ 67  │ Challenge 2018: Task 3: Test                  │ True   │ True   │ True   │ None            │\n",
            "│ 66  │ Challenge 2018: Task 3: Training              │ True   │ True   │ True   │ None            │\n",
            "│ 73  │ Challenge 2018: Task 3: Validation            │ True   │ True   │ True   │ None            │\n",
            "│ 65  │ Challenge 2019: Training                      │ True   │ True   │ True   │ None            │\n",
            "│ 70  │ Challenge 2020: Training                      │ True   │ True   │ True   │ None            │\n",
            "│ 97  │ Collection for ISBI 2016: 100 Lesion          │ True   │ False  │ True   │ None            │\n",
            "│     │ Classification                                │        │        │        │                 │\n",
            "│ 216 │ Consecutive biopsies for melanoma across year │ True   │ False  │ True   │ 10.34970/151324 │\n",
            "│     │ 2020                                          │        │        │        │                 │\n",
            "│ 75  │ Consumer AI apps                              │ True   │ False  │ True   │ 10.34970/401946 │\n",
            "│ 166 │ EASY Dermoscopy Expert Agreement Study        │ True   │ False  │ False  │ None            │\n",
            "│ 212 │ HAM10000                                      │ True   │ True   │ True   │ None            │\n",
            "│ 175 │ HIBA Skin Lesions                             │ True   │ False  │ True   │ 10.34970/559884 │\n",
            "│ 251 │ Hospital Italiano de Buenos Aires - Skin      │ True   │ False  │ True   │ 10.34970/587329 │\n",
            "│     │ Lesions Images (2019-2022)                    │        │        │        │                 │\n",
            "│ 176 │ Hospital Italiano de Buenos Aires Skin        │ True   │ False  │ True   │ 10.34970/432362 │\n",
            "│     │ Lesions                                       │        │        │        │                 │\n",
            "│ 217 │ Longitudinal overview images of posterior     │ True   │ False  │ True   │ 10.34970/630662 │\n",
            "│     │ trunks                                        │        │        │        │                 │\n",
            "│ 289 │ MSK-1                                         │ True   │ False  │ True   │ None            │\n",
            "│ 290 │ MSK-2                                         │ True   │ False  │ True   │ None            │\n",
            "│ 288 │ MSK-3                                         │ True   │ False  │ True   │ None            │\n",
            "│ 287 │ MSK-4                                         │ True   │ False  │ True   │ None            │\n",
            "│ 286 │ MSK-5                                         │ True   │ False  │ True   │ None            │\n",
            "│ 163 │ MSKCC Consecutive biopsies across year        │ True   │ False  │ True   │ None            │\n",
            "│     │ 2020_cohort                                   │        │        │        │                 │\n",
            "│ 77  │ Melanocytic lesions used for dermoscopic      │ True   │ False  │ True   │ 10.34970/108631 │\n",
            "│     │ feature annotations                           │        │        │        │                 │\n",
            "│ 294 │ Melanoma and Nevus Dermoscopy Images with     │ True   │ False  │ True   │ 10.34970/277003 │\n",
            "│     │ Confirmed Histopathological Diagnosis         │        │        │        │                 │\n",
            "│ 215 │ Newly-acquired and longer-existing acquired   │ True   │ False  │ True   │ 10.34970/408649 │\n",
            "│     │ melanoma and nevi                             │        │        │        │                 │\n",
            "│ 218 │ PROVe-AI                                      │ True   │ True   │ True   │ 10.34970/576276 │\n",
            "│ 328 │ Repeated Dermoscopic Images of Melanocytic    │ True   │ False  │ True   │ 10.34970/560760 │\n",
            "│     │ Lesions                                       │        │        │        │                 │\n",
            "│ 293 │ SONIC                                         │ True   │ False  │ True   │ None            │\n",
            "│ 292 │ UDA-1                                         │ True   │ False  │ True   │ None            │\n",
            "│ 291 │ UDA-2                                         │ True   │ False  │ True   │ None            │\n",
            "│ 285 │ lesions                                       │ True   │ False  │ False  │ None            │\n",
            "│ 172 │ screenshot_public_230207                      │ True   │ False  │ False  │ None            │\n",
            "└─────┴───────────────────────────────────────────────┴────────┴────────┴────────┴─────────────────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, concatenate, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "from google.colab import drive\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "Qydcku5hO9JU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPl5l2XioO78",
        "outputId": "5092f991-2133-4236-ea92-e453c156c969"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment out if already running"
      ],
      "metadata": {
        "id": "2RJkPIfDe5gt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the current path of kaggle.json file\n",
        "current_path = '/content/kaggle.json'\n",
        "\n",
        "# Desired path where the Kaggle API expects the kaggle.json file\n",
        "desired_path = '/root/.kaggle/kaggle.json'\n",
        "\n",
        "if os.path.exists(current_path):\n",
        "    os.makedirs(os.path.dirname(desired_path), exist_ok=True)\n",
        "    os.rename(current_path, desired_path)\n",
        "\n",
        "    # Set the file's permissions to avoid a permissions error\n",
        "    os.chmod(desired_path, 0o600)\n",
        "else:\n",
        "    print(f\"Error: '{current_path}' does not exist. Please upload the file.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "GxvlgkCfxBCt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "find the data set on kaggle\n",
        "\n",
        "Comment out if running and already have downloaded images"
      ],
      "metadata": {
        "id": "MZqQai6mypGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d andrewmvd/isic-2019\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPsM6paiysEU",
        "outputId": "3dbc997b-6a12-466d-9e23-8e82c5f1e5d7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading isic-2019.zip to /content\n",
            "100% 9.09G/9.10G [01:42<00:00, 121MB/s] \n",
            "100% 9.10G/9.10G [01:42<00:00, 95.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q isic-2019.zip\n"
      ],
      "metadata": {
        "id": "XlWuOA7dyxnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Data Preparation and Preprocessing\n",
        "DICOM Images\n",
        "\n",
        "DICOM Handling: Use pydicom to read DICOM files, which contain both the images and embedded metadata. For each DICOM file, extract the image data for preprocessing and the metadata for analysis.\n",
        "Image Preprocessing: Since DICOM images might not be uniformly sized, you may need to resize them to a standard size (e.g., 1024x1024) to match the TFRecord images, normalize pixel values, and potentially augment the data to improve model robustness.\n",
        "JPEG and TFRecord Images\n",
        "\n",
        "JPEG Handling: Directly read and preprocess (resize if necessary, normalize, augment).\n",
        "TFRecord Handling: Extract and preprocess. TFRecord files are already uniformly sized, which simplifies preprocessing.\n",
        "Metadata\n",
        "\n",
        "CSV Metadata: Load the metadata from CSV files. Clean and preprocess this data, which involves handling missing values, normalizing or scaling numerical features, and encoding categorical features.\n",
        "\n"
      ],
      "metadata": {
        "id": "1_BWFCj4QINb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the metadata\n",
        "\n",
        "and\n",
        "\n",
        "Explore the Metadata CSV: Load the metadata.csv files for training, test, and validation sets to understand the structure and types of data available. This step is crucial for preprocessing and feature selection."
      ],
      "metadata": {
        "id": "BW0CK9GitFSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the metadata\n",
        "metadata = pd.read_csv('/content/ISIC_2019_Training_Metadata.csv')\n",
        "\n",
        "# Display the first few rows of each DataFrame\n",
        "metadata.head()\n"
      ],
      "metadata": {
        "id": "HXZ38h4-2j6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth = pd.read_csv('/content/ISIC_2019_Training_GroundTruth.csv')\n",
        "ground_truth"
      ],
      "metadata": {
        "id": "DWo9AD0P5VwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV files\n",
        "ground_truth = pd.read_csv('/content/ISIC_2019_Training_GroundTruth.csv')\n",
        "metadata = pd.read_csv('/content/ISIC_2019_Training_Metadata.csv')\n",
        "\n",
        "image_dir = '/content/ISIC_2019_Training_Images'\n",
        "ground_truth['image_path'] = ground_truth['image'].apply(lambda x: os.path.join(image_dir, x + '.jpg'))\n",
        "\n",
        "# Merge the ground_truth with metadata if necessary\n",
        "full_metadata = pd.merge(ground_truth, metadata, on='image', how='left')  # Adjust 'on' parameter as needed\n",
        "full_metadata"
      ],
      "metadata": {
        "id": "gdODxFjP4Ydi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the image paths for the first few entries\n",
        "print(full_metadata['image_path'].head())\n"
      ],
      "metadata": {
        "id": "6Bzo5qSzHAk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correct the base path in 'image_path' column\n",
        "correct_base_path = \"/content/ISIC_2019_Training_Input/ISIC_2019_Training_Input\"\n",
        "\n",
        "full_metadata['image_path'] = full_metadata['image'].apply(lambda x: f\"{correct_base_path}/{x}.jpg\")\n",
        "\n",
        "# Verify the correction by printing the first few entries again\n",
        "print(full_metadata['image_path'].head())\n"
      ],
      "metadata": {
        "id": "_FDMb1wGHk3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_metadata.info()"
      ],
      "metadata": {
        "id": "0BjtJ7JO9mHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values for 'age_approx' with its median\n",
        "full_metadata['age_approx'].fillna(full_metadata['age_approx'].median(), inplace=True)\n",
        "\n",
        "# For categorical data, fill missing values with 'unknown'\n",
        "full_metadata['anatom_site_general'].fillna('unknown', inplace=True)\n",
        "full_metadata['sex'].fillna('unknown', inplace=True)\n"
      ],
      "metadata": {
        "id": "-W0QskH29_-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_metadata = pd.get_dummies(full_metadata, columns=['anatom_site_general', 'sex'])\n"
      ],
      "metadata": {
        "id": "sAeGNqs--IWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's separate features and labels first\n",
        "X = full_metadata.drop(['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC', 'UNK'], axis=1)\n",
        "y = full_metadata[['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC', 'UNK']]\n",
        "\n",
        "# Now, we split the data into training and testing sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split the X_temp and y_temp further into validation and test sets\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "3xBB1t4rEGjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, y_train.shape)\n",
        "print(X_val.shape, y_val.shape)\n",
        "print(X_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "id": "NcKsOCJcaFiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dual Input Generator for creating a mo"
      ],
      "metadata": {
        "id": "86lCVqd8qSaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DualInputGenerator(Sequence):\n",
        "    def __init__(self, image_paths, metadata, labels, batch_size, img_size=(224, 224), shuffle=True):\n",
        "        self.image_paths = image_paths\n",
        "        self.metadata = metadata\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.shuffle = shuffle\n",
        "        self.indexes = np.arange(len(self.image_paths))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.image_paths) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "        # Initialization\n",
        "        X_images = np.empty((self.batch_size, *self.img_size, 3))\n",
        "        X_metadata = np.empty((self.batch_size, self.metadata.shape[1]))\n",
        "        y = np.empty((self.batch_size, self.labels.shape[1]), dtype=int)\n",
        "\n",
        "        # Generate data\n",
        "        for i, batch_index in enumerate(batch_indexes):\n",
        "            # Load and preprocess image\n",
        "            img_path = os.path.join('/content/ISIC_2019_Training_Input/ISIC_2019_Training_Input/', self.image_paths[batch_index])\n",
        "            img = load_img(img_path, target_size=self.img_size)\n",
        "            X_images[i,] = img_to_array(img) / 255.0\n",
        "\n",
        "            # Load metadata\n",
        "            X_metadata[i,] = self.metadata[batch_index]\n",
        "\n",
        "            # Load label\n",
        "            y[i,] = self.labels[batch_index]\n",
        "\n",
        "        return [X_images, X_metadata], y\n",
        "\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n"
      ],
      "metadata": {
        "id": "pP09P7wGBGD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the training generator\n",
        "train_gen = DualInputGenerator(\n",
        "    image_paths=X_train['image_path'].values,\n",
        "    metadata=X_train.drop(columns=['image', 'image_path', 'lesion_id']).values,\n",
        "    labels=y_train.values,  # Include labels for training set\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# Initialize the validation generator\n",
        "val_gen = DualInputGenerator(\n",
        "    image_paths=X_val['image_path'].values,\n",
        "    metadata=X_val.drop(columns=['image', 'image_path', 'lesion_id']).values,\n",
        "    labels=y_val.values,  # Include labels for validation set\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# Initialize the test generator\n",
        "test_gen = DualInputGenerator(\n",
        "    image_paths=X_test['image_path'].values,\n",
        "    metadata=X_test.drop(columns=['image', 'image_path', 'lesion_id']).values,\n",
        "    labels=y_test.values,  # Include labels for test set\n",
        "    batch_size=32\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "8gD1J3reWT-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "define a dual input model\n"
      ],
      "metadata": {
        "id": "Hg7trvZfbOp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_metadata_features = X_train.drop(columns=['image', 'image_path', 'lesion_id']).shape[1]\n",
        "print(\"Number of metadata features:\", num_metadata_features)\n"
      ],
      "metadata": {
        "id": "JUTOAkX0lHTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load EfficientNetB0 as the base model\n",
        "base_model = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "base_model.trainable = False  # Freeze EfficientNet model\n",
        "\n",
        "# Image processing branch\n",
        "image_input = base_model.input\n",
        "x = base_model(image_input)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "image_branch = Dense(128, activation='relu')(x)\n",
        "\n",
        "# Metadata input branch\n",
        "metadata_input = Input(shape=(13,), name='metadata_input')  # num_metadata_features defined based on your dataset\n",
        "y = Dense(32, activation='relu')(metadata_input)\n",
        "metadata_branch = Dense(64, activation='relu')(y)\n",
        "\n",
        "# Combine branches\n",
        "number_of_classes = y_train.shape[1]\n",
        "combined = concatenate([image_branch, metadata_branch])\n",
        "z = Dense(256, activation='relu')(combined)\n",
        "z = Dropout(0.5)(z)\n",
        "output = Dense(number_of_classes, activation='softmax')(z)  # number_of_classes defined based on your dataset\n",
        "\n",
        "# Final model\n",
        "model = Model(inputs=[image_input, metadata_input], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "EOCCRKIH6pE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "instal a checkpoint for this, since the rentime exceeds several hours"
      ],
      "metadata": {
        "id": "nZwoAjGnmiVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint_path = \"/content/drive/My Drive/your_model_directory/model-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', verbose=3, save_best_only=True, mode='max')"
      ],
      "metadata": {
        "id": "WMPKC0Z4mid1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Juice it UP!"
      ],
      "metadata": {
        "id": "YNvngdCeoEVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
      ],
      "metadata": {
        "id": "SC3rn85NqvsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.debugging.set_log_device_placement(True)\n",
        "\n",
        "# Test with a simple computation\n",
        "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
        "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
        "# Run on GPU\n",
        "c = tf.matmul(a, b)\n",
        "\n",
        "print(c)\n"
      ],
      "metadata": {
        "id": "LbV-J3q1qz8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First Run without pretrained generators"
      ],
      "metadata": {
        "id": "jtj_1lin7bTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=10,\n",
        "    steps_per_epoch=len(train_gen),\n",
        "    validation_steps=len(val_gen)\n",
        ")"
      ],
      "metadata": {
        "id": "WLl2o01CaEbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_gen, steps=len(test_gen))\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "id": "DXSsK7n7P0Ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets save this model\n"
      ],
      "metadata": {
        "id": "z2AWRmDMpZ5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "-j1vR9VcpZGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Generate a plot of the model\n",
        "plot_model(model, to_file='model_diagram.png', show_shapes=True, show_layer_names=True)\n"
      ],
      "metadata": {
        "id": "7ptED-jnpdpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "# Display the model diagram\n",
        "Image('model_diagram.png')\n"
      ],
      "metadata": {
        "id": "8TBc89IZpdzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint_path = \"/content/drive/My Drive/your_model_directory/model-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n"
      ],
      "metadata": {
        "id": "wDDFvHxTpd7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "66.46% is ok, but lets do some fine tuning"
      ],
      "metadata": {
        "id": "e4WEe_Pe4GPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze some or all of the base model layers\n",
        "base_model.trainable = True\n",
        "\n",
        "# It's important to recompile the model after making any changes to the `trainable` attribute of any layer\n",
        "model.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fine-tune the model\n",
        "history_fine = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=5  # Adjust the number of epochs for fine-tuning\n",
        ")\n"
      ],
      "metadata": {
        "id": "5c_BmO5Z4Ext"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n"
      ],
      "metadata": {
        "id": "SvuZbLFy4E2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hOmu7Opz4E7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: User Interface (UI)\n",
        "A simple web-based UI allows users to upload lesion images, input relevant metadata, and receive a prediction. We will use Gradio as learned in class for this model."
      ],
      "metadata": {
        "id": "Y_b53V90Dlbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install gradio"
      ],
      "metadata": {
        "id": "iZPbWw523sBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "vJ11PNQbghbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(img):\n",
        "    # Assuming 'model' is your trained dual-input model\n",
        "    # Preprocess the image to match your model's expected input\n",
        "    img = img.resize((224, 224))  # Resize image\n",
        "    img_array = image.img_to_array(img) / 255.0  # Convert to array and normalize\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Example: Placeholder for metadata, replace with actual expected metadata\n",
        "    metadata = np.zeros((1, num_metadata_features))  # You'll need to replace this with actual metadata handling\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict([img_array, metadata])  # Dual input: image and metadata\n",
        "\n",
        "    # Assuming you have a function to process your model's output into a human-readable form\n",
        "    readable_prediction = process_prediction(prediction)  # Implement this function based on your model's output\n",
        "\n",
        "    return readable_prediction\n",
        "\n",
        "# Create a Gradio interface\n",
        "iface = gr.Interface(fn=predict_image,\n",
        "                     inputs=gr.inputs.Image(shape=(224, 224)),\n",
        "                     outputs=\"text\",\n",
        "                     title=\"Skin Lesion Classifier\",\n",
        "                     description=\"Upload an image of a skin lesion to predict its type.\")\n",
        "\n",
        "# Launch the app\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "4ScKLPLIP2u8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we will want to enhance image upload by filling out as much metadata as possible on the input side"
      ],
      "metadata": {
        "id": "MNK6rfsrgn20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a prediction function that includes metadata inputs\n",
        "def predict_image_with_metadata(img, age, sex, location):\n",
        "    # Preprocess inputs as needed\n",
        "    # For example, you would need to convert 'sex' and 'location' into the format your model expects (e.g., one-hot encoded)\n",
        "\n",
        "    # Make prediction using preprocessed image and metadata\n",
        "    # prediction = model.predict(...)\n",
        "\n",
        "    # Convert prediction to readable format\n",
        "    return process_prediction(prediction)\n",
        "\n",
        "# Create Gradio interface with additional metadata inputs\n",
        "iface = gr.Interface(fn=predict_image_with_metadata,\n",
        "                     inputs=[gr.inputs.Image(shape=(224, 224)),\n",
        "                             gr.inputs.Number(label=\"Age\"),\n",
        "                             gr.inputs.Radio(['Male', 'Female', 'Other'], label=\"Sex\"),\n",
        "                             gr.inputs.Dropdown(['Head/Neck', 'Upper Extremity', 'Lower Extremity', 'Torso', 'Palms/Soles', 'Oral/Genital', 'Other'], label=\"Anatomical Site\")],\n",
        "                     outputs=\"text\",\n",
        "                     title=\"Skin Lesion Classifier\",\n",
        "                     description=\"Upload an image of a skin lesion and enter metadata to predict its type.\")\n",
        "\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "Mia2UwDQgwaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we will need to preprocess the uploaded imagages"
      ],
      "metadata": {
        "id": "wR4WjoKEhEEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_image(uploaded_image):\n",
        "    \"\"\"\n",
        "    Preprocess the uploaded image to match the model's expected input format.\n",
        "    \"\"\"\n",
        "    # Resize the image to the required dimensions\n",
        "    img = uploaded_image.resize((224, 224))\n",
        "\n",
        "    # Convert the image to a numpy array\n",
        "    img_array = np.array(img)\n",
        "\n",
        "    # Ensure the image has 3 color channels (RGB)\n",
        "    if img_array.ndim == 2:\n",
        "        img_array = np.stack((img_array,)*3, axis=-1)\n",
        "\n",
        "    # Normalize pixel values to [0, 1]\n",
        "    img_array = img_array / 255.0\n",
        "\n",
        "    # Add a batch dimension\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    return img_array\n",
        "\n",
        "def predict_image(uploaded_image):\n",
        "    # Preprocess the uploaded image\n",
        "    preprocessed_image = preprocess_image(uploaded_image)\n",
        "\n",
        "    # Assuming 'model' is your trained model\n",
        "    prediction = model.predict(preprocessed_image)\n",
        "\n",
        "    # Process the prediction to generate a human-readable result\n",
        "    readable_prediction = process_prediction(prediction)  # Implement this based on your model's specifics\n",
        "\n",
        "    return readable_prediction\n"
      ],
      "metadata": {
        "id": "Mu9it6yng3rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ok, lets finish the workflow by making a prediction on the preprocessed image"
      ],
      "metadata": {
        "id": "zsqTPa3RhUkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diagnosis_descriptions = {\n",
        "    'MEL': 'Melanoma: a serious form of skin cancer that begins in cells known as melanocytes.',\n",
        "    'NV': 'Melanocytic nevus: a common type of skin growth that often appears as a small, dark brown spot.',\n",
        "    'BCC': 'Basal cell carcinoma: a type of skin cancer that most often develops on areas exposed to the sun.',\n",
        "    'AK': 'Actinic keratosis: a rough, scaly patch on the skin caused by years of sun exposure.',\n",
        "    'BKL': 'Benign keratosis: a non-cancerous skin condition that appears as a waxy brown, black, or tan growth.',\n",
        "    'DF': 'Dermatofibroma: a common growth on the skin, usually found on the lower legs, that can be pink, red, or brown.',\n",
        "    'VASC': 'Vascular lesion: a type of abnormal growth or mark on the skin that is made up of blood vessels.',\n",
        "    'SCC': 'Squamous cell carcinoma: a common form of skin cancer that develops in the squamous cells.',\n",
        "    'UNK': 'None of the others: the lesion does not fit into any of the other categories.'\n",
        "}\n"
      ],
      "metadata": {
        "id": "M3H3C8nki6Hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_explain(image):\n",
        "    preprocessed_image = preprocess_image(image)\n",
        "    prediction = model.predict(preprocessed_image)\n",
        "    predicted_class_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "    # Assuming your model's output classes are ordered as listed in diagnosis_descriptions\n",
        "    class_keys = list(diagnosis_descriptions.keys())\n",
        "    predicted_class_key = class_keys[predicted_class_index]\n",
        "\n",
        "    # Fetch the description\n",
        "    description = diagnosis_descriptions[predicted_class_key]\n",
        "\n",
        "    return predicted_class_key, description\n",
        "\n"
      ],
      "metadata": {
        "id": "VWZIwfpog35x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "and then display the prediction"
      ],
      "metadata": {
        "id": "BFt67ejfhjB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradio_predict(image):\n",
        "    class_key, description = predict_and_explain(image)\n",
        "    return f\"Diagnosis: {class_key} ({description})\"\n",
        "\n",
        "iface = gr.Interface(fn=gradio_predict,\n",
        "                     inputs=gr.inputs.Image(shape=(224, 224)),\n",
        "                     outputs=\"text\",\n",
        "                     title=\"Skin Lesion Classifier\",\n",
        "                     description=\"Upload an image of a skin lesion to predict its type and get more information.\")\n",
        "iface.launch()\n",
        "\n"
      ],
      "metadata": {
        "id": "Szoo_j0ghmz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Integrate APIs\n",
        "\n",
        "If using OpenAI's GPT-3, you'll interact with it through its API, sending requests with the classification results and receiving generated text.\n",
        "If your application needs to store or retrieve data, consider integrating a database and accessing it through a REST API.\n"
      ],
      "metadata": {
        "id": "YmPKZljKP01V"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O6NC2xqZP72A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a3NfZZ-6P8Xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Build the Application Logic\n",
        "\n",
        "Develop a user interface where users can upload photos of skin growths.\n",
        "After uploading, the photo is sent to the image classification model to determine the type of growth.\n",
        "The classification result is used to generate a prompt for the ChatGPT-like model, which then creates an informative response.\n",
        "Display the response to the user along with any additional advice or recommendations."
      ],
      "metadata": {
        "id": "Pvmr3cJZP838"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9tcXjuvnP_1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uGcwSi8sQAbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CWdf2KnwQAkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "p93HB7t2QA9P"
      }
    }
  ]
}